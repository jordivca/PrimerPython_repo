{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf93d8bb",
   "metadata": {},
   "source": [
    "# Ejercicio ETL 1 basic-Carga\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bd24cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#algunas librerias importantes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83ea785b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Importando las librerias\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "# Seteamos el directorio a buscar los archivos\n",
    "path = r'C:\\Users\\LUIGGI\\Desktop\\Curso_ETL_Python\\ETL DATASET\\World Cup\\Raw'\n",
    "#cambiamos el path\n",
    "os.chdir(path)\n",
    "#\n",
    "files = glob.glob( '*.csv')\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf3933c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe creado exitosamente para Diciembre_2022.csv con un tamañao (24, 6)\n",
      "Dataframe creado exitosamente para Noviembre_2022.csv con un tamañao (40, 6)\n",
      "(64, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Home</th>\n",
       "      <th>Away</th>\n",
       "      <th>Attendance</th>\n",
       "      <th>Venue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01 December 2022</td>\n",
       "      <td>18:00 (20:30)</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Morocco</td>\n",
       "      <td>43,102</td>\n",
       "      <td>Al Thumama Stadium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01 December 2022</td>\n",
       "      <td>18:00 (20:30)</td>\n",
       "      <td>Croatia</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>43,984</td>\n",
       "      <td>Ahmed bin Ali Stadium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01 December 2022</td>\n",
       "      <td>22:00 (00:30)</td>\n",
       "      <td>Costa Rica</td>\n",
       "      <td>Germany</td>\n",
       "      <td>67,054</td>\n",
       "      <td>Al Bayt Stadium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01 December 2022</td>\n",
       "      <td>22:00 (00:30)</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Spain</td>\n",
       "      <td>44,851</td>\n",
       "      <td>Khalifa International Stadium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02 December 2022</td>\n",
       "      <td>18:00 (20:30)</td>\n",
       "      <td>Korea Republic</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>44,097</td>\n",
       "      <td>Education City Stadium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date           Time            Home      Away Attendance  \\\n",
       "0  01 December 2022  18:00 (20:30)          Canada   Morocco     43,102   \n",
       "1  01 December 2022  18:00 (20:30)         Croatia   Belgium     43,984   \n",
       "2  01 December 2022  22:00 (00:30)     Costa Rica    Germany     67,054   \n",
       "3  01 December 2022  22:00 (00:30)           Japan     Spain     44,851   \n",
       "4  02 December 2022  18:00 (20:30)  Korea Republic  Portugal     44,097   \n",
       "\n",
       "                           Venue  \n",
       "0             Al Thumama Stadium  \n",
       "1          Ahmed bin Ali Stadium  \n",
       "2                Al Bayt Stadium  \n",
       "3  Khalifa International Stadium  \n",
       "4         Education City Stadium  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos una lista en blanco para cargar los datasets\n",
    "li = []\n",
    "# Realizaremos un loop sobre cada archivo, lo leeremos y lo juntaremos.\n",
    "\n",
    "for f in files:\n",
    "    # Leemos el archivo\n",
    "    temp_df = pd.read_csv(f ,sep=';')\n",
    "    # agregamos a la lista los dataframes\n",
    "    li.append(temp_df)\n",
    "    print(f'Dataframe creado exitosamente para {f} con un tamañao {temp_df.shape}')\n",
    "\n",
    "# Uniremos todos los dataframe en uno\n",
    "df = pd.concat(li, axis=0)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21639f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pasemos el codigo a un Py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72314201",
   "metadata": {},
   "source": [
    "# Ejercicio ETL 1 Basic-Carga-Mejorado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d273086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Away</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01 December 2022</td>\n",
       "      <td>18:00 (20:30)</td>\n",
       "      <td>Morocco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01 December 2022</td>\n",
       "      <td>18:00 (20:30)</td>\n",
       "      <td>Belgium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01 December 2022</td>\n",
       "      <td>22:00 (00:30)</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01 December 2022</td>\n",
       "      <td>22:00 (00:30)</td>\n",
       "      <td>Spain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02 December 2022</td>\n",
       "      <td>18:00 (20:30)</td>\n",
       "      <td>Portugal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>02 December 2022</td>\n",
       "      <td>18:00 (20:30)</td>\n",
       "      <td>Uruguay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>02 December 2022</td>\n",
       "      <td>22:00 (00:30)</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>02 December 2022</td>\n",
       "      <td>22:00 (00:30)</td>\n",
       "      <td>Switzerland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>03 December 2022</td>\n",
       "      <td>18:00 (20:30)</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>03 December 2022</td>\n",
       "      <td>22:00 (00:30)</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>04 December 2022</td>\n",
       "      <td>18:00 (20:30)</td>\n",
       "      <td>Poland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>04 December 2022</td>\n",
       "      <td>22:00 (00:30)</td>\n",
       "      <td>Senegal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>05 December 2022</td>\n",
       "      <td>18:00 (20:30)</td>\n",
       "      <td>Croatia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>05 December 2022</td>\n",
       "      <td>22:00 (00:30)</td>\n",
       "      <td>Korea Republic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>06 December 2022</td>\n",
       "      <td>18:00 (20:30)</td>\n",
       "      <td>Spain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>06 December 2022</td>\n",
       "      <td>22:00 (00:30)</td>\n",
       "      <td>Switzerland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>09 December 2022</td>\n",
       "      <td>18:00 (20:30)</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>09 December 2022</td>\n",
       "      <td>22:00 (00:30)</td>\n",
       "      <td>Argentina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10 December 2022</td>\n",
       "      <td>18:00 (20:30)</td>\n",
       "      <td>Portugal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10 December 2022</td>\n",
       "      <td>22:00 (00:30)</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>13 December 2022</td>\n",
       "      <td>22:00 (00:30)</td>\n",
       "      <td>Croatia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>14 December 2022</td>\n",
       "      <td>22:00 (00:30)</td>\n",
       "      <td>Morocco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>17 December 2022</td>\n",
       "      <td>18:00 (20:30)</td>\n",
       "      <td>Morocco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>18 December 2022</td>\n",
       "      <td>18:00 (20:30)</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Date           Time            Away\n",
       "0   01 December 2022  18:00 (20:30)         Morocco\n",
       "1   01 December 2022  18:00 (20:30)         Belgium\n",
       "2   01 December 2022  22:00 (00:30)         Germany\n",
       "3   01 December 2022  22:00 (00:30)           Spain\n",
       "4   02 December 2022  18:00 (20:30)        Portugal\n",
       "5   02 December 2022  18:00 (20:30)         Uruguay\n",
       "6   02 December 2022  22:00 (00:30)          Brazil\n",
       "7   02 December 2022  22:00 (00:30)     Switzerland\n",
       "8   03 December 2022  18:00 (20:30)             USA\n",
       "9   03 December 2022  22:00 (00:30)       Australia\n",
       "10  04 December 2022  18:00 (20:30)          Poland\n",
       "11  04 December 2022  22:00 (00:30)         Senegal\n",
       "12  05 December 2022  18:00 (20:30)         Croatia\n",
       "13  05 December 2022  22:00 (00:30)  Korea Republic\n",
       "14  06 December 2022  18:00 (20:30)           Spain\n",
       "15  06 December 2022  22:00 (00:30)     Switzerland\n",
       "16  09 December 2022  18:00 (20:30)          Brazil\n",
       "17  09 December 2022  22:00 (00:30)       Argentina\n",
       "18  10 December 2022  18:00 (20:30)        Portugal\n",
       "19  10 December 2022  22:00 (00:30)          France\n",
       "20  13 December 2022  22:00 (00:30)         Croatia\n",
       "21  14 December 2022  22:00 (00:30)         Morocco\n",
       "22  17 December 2022  18:00 (20:30)         Morocco\n",
       "23  18 December 2022  18:00 (20:30)          France"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#crearemos una funcion para leer solo algunas columnas\n",
    "\n",
    "def leer_csv(path=\"\",column_name =[] , sep=';'):\n",
    "    \n",
    "    if len(column_name) == 0:\n",
    "        \n",
    "        df = pd.read_csv(path, sep=';')\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        df = pd.read_csv(path,usecols = column_name, sep=';')\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "leer_csv(path=files[0] ,column_name =[\"Date\", \"Time\", \"Away\"], sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66c1880b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Diciembre_2022.csv', 'Noviembre_2022.csv']\n"
     ]
    }
   ],
   "source": [
    "# Importando las librerias\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "# Seteamos el directorio a buscar los archivos\n",
    "path = r'C:/Users/LUIGGI/Desktop/Curso_ETL_Python/ETL DATASET/World Cup/Raw'\n",
    "#cambiamos el path\n",
    "os.chdir(path)\n",
    "# vamos  a buscar todos los archivos que son csv\n",
    "files = glob.glob('*.csv')\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75829d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe creado exitosamente para Diciembre_2022.csv con un tamañao (24, 6)\n",
      "Dataframe creado exitosamente para Noviembre_2022.csv con un tamañao (40, 6)\n",
      "(64, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Home</th>\n",
       "      <th>Away</th>\n",
       "      <th>Attendance</th>\n",
       "      <th>Venue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01 December 2022</td>\n",
       "      <td>18:00 (20:30)</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Morocco</td>\n",
       "      <td>43,102</td>\n",
       "      <td>Al Thumama Stadium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01 December 2022</td>\n",
       "      <td>18:00 (20:30)</td>\n",
       "      <td>Croatia</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>43,984</td>\n",
       "      <td>Ahmed bin Ali Stadium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01 December 2022</td>\n",
       "      <td>22:00 (00:30)</td>\n",
       "      <td>Costa Rica</td>\n",
       "      <td>Germany</td>\n",
       "      <td>67,054</td>\n",
       "      <td>Al Bayt Stadium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01 December 2022</td>\n",
       "      <td>22:00 (00:30)</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Spain</td>\n",
       "      <td>44,851</td>\n",
       "      <td>Khalifa International Stadium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02 December 2022</td>\n",
       "      <td>18:00 (20:30)</td>\n",
       "      <td>Korea Republic</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>44,097</td>\n",
       "      <td>Education City Stadium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date           Time            Home      Away Attendance  \\\n",
       "0  01 December 2022  18:00 (20:30)          Canada   Morocco     43,102   \n",
       "1  01 December 2022  18:00 (20:30)         Croatia   Belgium     43,984   \n",
       "2  01 December 2022  22:00 (00:30)     Costa Rica    Germany     67,054   \n",
       "3  01 December 2022  22:00 (00:30)           Japan     Spain     44,851   \n",
       "4  02 December 2022  18:00 (20:30)  Korea Republic  Portugal     44,097   \n",
       "\n",
       "                           Venue  \n",
       "0             Al Thumama Stadium  \n",
       "1          Ahmed bin Ali Stadium  \n",
       "2                Al Bayt Stadium  \n",
       "3  Khalifa International Stadium  \n",
       "4         Education City Stadium  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "# Creamos una lista en blanco para cargar los datasets\n",
    "li = []\n",
    "# Realizaremos un loop sobre cada archivo, lo leeremos y lo juntaremos.\n",
    "path_salida = r'C:/Users/LUIGGI/Desktop/Curso_ETL_Python/ETL DATASET/World Cup/Procesado/'\n",
    "\n",
    "for f in files:\n",
    "    # Leemos el archivo\n",
    "    temp_df = leer_csv(f ,sep=';')\n",
    "    # agregamos a la lista los dataframes\n",
    "    li.append(temp_df)\n",
    "    \n",
    "    #Moviendo archivos a la capa de Procesado\n",
    "    shutil.move(f, path_salida+f)\n",
    "\n",
    "    print(f'Dataframe creado exitosamente para {f} con un tamañao {temp_df.shape}')\n",
    "\n",
    "# Uniremos todos los dataframe en uno\n",
    "df = pd.concat(li, axis=0)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eca28da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_final = r'C:/Users/LUIGGI/Desktop/Curso_ETL_Python/ETL DATASET/World Cup/Consolidado/'\n",
    "\n",
    "df.to_csv(path_final+\"FInal.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec676b1",
   "metadata": {},
   "source": [
    "# Ejercicio ETL 2 Intermedio-Carga"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c66661",
   "metadata": {},
   "source": [
    "### CREANDO SEGMENTACION DE LOS DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4602c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Archivo_procesado.xlsx', 'Consolidado.xlsx', 'Sample - Superstore.xlsx', '~$Sample - Superstore.xlsx']\n"
     ]
    }
   ],
   "source": [
    "# Importando las librerias\n",
    "#!pip install openpyxl\n",
    "import pandas as pd\n",
    "import glob\n",
    "# Seteamos el directorio a buscar los archivos\n",
    "# vamos  a buscar todos los archivos que son csv\n",
    "path = r'C:\\Users\\LUIGGI\\Desktop\\Curso_ETL_Python\\ETL DATASET\\Dataset_ ventas'\n",
    "#cambiamos el path\n",
    "os.chdir(path)\n",
    "files = glob.glob( '*.xlsx')\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da3d9e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos el archivo\n",
    "df = pd.read_excel(files[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1347b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recorremos por año y por mes\n",
    "year = df['Order Date'].dt.year.unique()\n",
    "month = df['Order Date'].dt.month.unique()\n",
    "#realizamos el cambio de numero por mes \n",
    "dic = {1:\"Enero\", 2:\"Febrero\", 3:\"Marzo\", 4:\"Abril\", 5:\"Mayo\", 6:\"Junio\", 7:\"Julio\", 8:\"Agosto\", 9:\"Septiembre\", 10:\"Octubre\", 11:\"Noviembre\", 12:\"Diciembre\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8959e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2016, 2015, 2014, 2017], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b8eebe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11,  6, 10,  4, 12,  5,  8,  7,  9,  1,  3,  2], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0903918",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realizamos un loop por año y mes\n",
    "for y in year:\n",
    "    if not os.path.exists(path+\"\\\\\"+str(y)):\n",
    "            os.mkdir(path+\"\\\\\"+str(y))\n",
    "    for m in month:\n",
    "        tmp = df[(df['Order Date'].dt.year==y) & (df['Order Date'].dt.month==m) ]\n",
    "        #Si la ruta no existe la creara\n",
    "        if not os.path.exists(path+\"\\\\\"+str(y)+\"\\\\\"+dic.get(m)):\n",
    "            os.mkdir(path+\"\\\\\"+str(y)+\"\\\\\"+dic.get(m))\n",
    "        tmp.to_excel(path+\"\\\\\"+str(y)+\"\\\\\"+dic.get(m)+\"\\\\\"+str(y)+dic.get(m)+\".xlsx\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aca3e36",
   "metadata": {},
   "source": [
    "### Leyendo los datos de la  subcarpetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "feef1b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: tqdm in d:\\bcp\\algortimo\\curso_etl_python\\lib\\site-packages (4.64.1)\n",
      "Requirement already satisfied: colorama in d:\\bcp\\algortimo\\curso_etl_python\\lib\\site-packages (from tqdm) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm\n",
    "import tqdm\n",
    "path = r'C:\\Users\\LUIGGI\\Desktop\\Curso_ETL_Python\\ETL DATASET\\Dataset_ ventas'\n",
    "\n",
    "# Creare una lista para guardar los dataframe\n",
    "procesado = []\n",
    "\n",
    "#creare una lista para guardar los archivos procesados\n",
    "archivo_procesado = []\n",
    "\n",
    "archivo_por_procesar = glob.glob(f'{path}/*/**/*.xlsx', recursive=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "810b5cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Archivo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\LUIGGI\\Desktop\\Curso_ETL_Python\\ETL D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\LUIGGI\\Desktop\\Curso_ETL_Python\\ETL D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\LUIGGI\\Desktop\\Curso_ETL_Python\\ETL D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\LUIGGI\\Desktop\\Curso_ETL_Python\\ETL D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\LUIGGI\\Desktop\\Curso_ETL_Python\\ETL D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C:\\Users\\LUIGGI\\Desktop\\Curso_ETL_Python\\ETL D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C:\\Users\\LUIGGI\\Desktop\\Curso_ETL_Python\\ETL D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C:\\Users\\LUIGGI\\Desktop\\Curso_ETL_Python\\ETL D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C:\\Users\\LUIGGI\\Desktop\\Curso_ETL_Python\\ETL D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C:\\Users\\LUIGGI\\Desktop\\Curso_ETL_Python\\ETL D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>C:\\Users\\LUIGGI\\Desktop\\Curso_ETL_Python\\ETL D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>C:\\Users\\LUIGGI\\Desktop\\Curso_ETL_Python\\ETL D...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Archivo\n",
       "0   C:\\Users\\LUIGGI\\Desktop\\Curso_ETL_Python\\ETL D...\n",
       "1   C:\\Users\\LUIGGI\\Desktop\\Curso_ETL_Python\\ETL D...\n",
       "2   C:\\Users\\LUIGGI\\Desktop\\Curso_ETL_Python\\ETL D...\n",
       "3   C:\\Users\\LUIGGI\\Desktop\\Curso_ETL_Python\\ETL D...\n",
       "4   C:\\Users\\LUIGGI\\Desktop\\Curso_ETL_Python\\ETL D...\n",
       "5   C:\\Users\\LUIGGI\\Desktop\\Curso_ETL_Python\\ETL D...\n",
       "6   C:\\Users\\LUIGGI\\Desktop\\Curso_ETL_Python\\ETL D...\n",
       "7   C:\\Users\\LUIGGI\\Desktop\\Curso_ETL_Python\\ETL D...\n",
       "8   C:\\Users\\LUIGGI\\Desktop\\Curso_ETL_Python\\ETL D...\n",
       "9   C:\\Users\\LUIGGI\\Desktop\\Curso_ETL_Python\\ETL D...\n",
       "10  C:\\Users\\LUIGGI\\Desktop\\Curso_ETL_Python\\ETL D...\n",
       "11  C:\\Users\\LUIGGI\\Desktop\\Curso_ETL_Python\\ETL D..."
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Leer\n",
    "archivo = pd.read_excel(\"Archivo_procesado.xlsx\")\n",
    "archivo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "96b40ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validamos los archivos que no se han procesado\n",
    "for x in archivo['Archivo']:\n",
    "    archivo_por_procesar.remove(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "60be9191",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\LUIGGI\\\\Desktop\\\\Curso_ETL_Python\\\\ETL DATASET\\\\Dataset_ ventas\\\\2014\\\\Abril\\\\2014Abril.xlsx',\n",
       " 'C:\\\\Users\\\\LUIGGI\\\\Desktop\\\\Curso_ETL_Python\\\\ETL DATASET\\\\Dataset_ ventas\\\\2014\\\\Agosto\\\\2014Agosto.xlsx',\n",
       " 'C:\\\\Users\\\\LUIGGI\\\\Desktop\\\\Curso_ETL_Python\\\\ETL DATASET\\\\Dataset_ ventas\\\\2014\\\\Diciembre\\\\2014Diciembre.xlsx',\n",
       " 'C:\\\\Users\\\\LUIGGI\\\\Desktop\\\\Curso_ETL_Python\\\\ETL DATASET\\\\Dataset_ ventas\\\\2014\\\\Enero\\\\2014Enero.xlsx',\n",
       " 'C:\\\\Users\\\\LUIGGI\\\\Desktop\\\\Curso_ETL_Python\\\\ETL DATASET\\\\Dataset_ ventas\\\\2014\\\\Febrero\\\\2014Febrero.xlsx',\n",
       " 'C:\\\\Users\\\\LUIGGI\\\\Desktop\\\\Curso_ETL_Python\\\\ETL DATASET\\\\Dataset_ ventas\\\\2014\\\\Julio\\\\2014Julio.xlsx',\n",
       " 'C:\\\\Users\\\\LUIGGI\\\\Desktop\\\\Curso_ETL_Python\\\\ETL DATASET\\\\Dataset_ ventas\\\\2014\\\\Junio\\\\2014Junio.xlsx',\n",
       " 'C:\\\\Users\\\\LUIGGI\\\\Desktop\\\\Curso_ETL_Python\\\\ETL DATASET\\\\Dataset_ ventas\\\\2014\\\\Marzo\\\\2014Marzo.xlsx',\n",
       " 'C:\\\\Users\\\\LUIGGI\\\\Desktop\\\\Curso_ETL_Python\\\\ETL DATASET\\\\Dataset_ ventas\\\\2014\\\\Mayo\\\\2014Mayo.xlsx',\n",
       " 'C:\\\\Users\\\\LUIGGI\\\\Desktop\\\\Curso_ETL_Python\\\\ETL DATASET\\\\Dataset_ ventas\\\\2014\\\\Noviembre\\\\2014Noviembre.xlsx',\n",
       " 'C:\\\\Users\\\\LUIGGI\\\\Desktop\\\\Curso_ETL_Python\\\\ETL DATASET\\\\Dataset_ ventas\\\\2014\\\\Octubre\\\\2014Octubre.xlsx',\n",
       " 'C:\\\\Users\\\\LUIGGI\\\\Desktop\\\\Curso_ETL_Python\\\\ETL DATASET\\\\Dataset_ ventas\\\\2014\\\\Septiembre\\\\2014Septiembre.xlsx',\n",
       " 'C:\\\\Users\\\\LUIGGI\\\\Desktop\\\\Curso_ETL_Python\\\\ETL DATASET\\\\Dataset_ ventas\\\\2015\\\\Abril\\\\2015Abril.xlsx',\n",
       " 'C:\\\\Users\\\\LUIGGI\\\\Desktop\\\\Curso_ETL_Python\\\\ETL DATASET\\\\Dataset_ ventas\\\\2015\\\\Agosto\\\\2015Agosto.xlsx',\n",
       " 'C:\\\\Users\\\\LUIGGI\\\\Desktop\\\\Curso_ETL_Python\\\\ETL DATASET\\\\Dataset_ ventas\\\\2015\\\\Diciembre\\\\2015Diciembre.xlsx',\n",
       " 'C:\\\\Users\\\\LUIGGI\\\\Desktop\\\\Curso_ETL_Python\\\\ETL DATASET\\\\Dataset_ ventas\\\\2015\\\\Enero\\\\2015Enero.xlsx',\n",
       " 'C:\\\\Users\\\\LUIGGI\\\\Desktop\\\\Curso_ETL_Python\\\\ETL DATASET\\\\Dataset_ ventas\\\\2015\\\\Febrero\\\\2015Febrero.xlsx',\n",
       " 'C:\\\\Users\\\\LUIGGI\\\\Desktop\\\\Curso_ETL_Python\\\\ETL DATASET\\\\Dataset_ ventas\\\\2015\\\\Julio\\\\2015Julio.xlsx',\n",
       " 'C:\\\\Users\\\\LUIGGI\\\\Desktop\\\\Curso_ETL_Python\\\\ETL DATASET\\\\Dataset_ ventas\\\\2015\\\\Junio\\\\2015Junio.xlsx',\n",
       " 'C:\\\\Users\\\\LUIGGI\\\\Desktop\\\\Curso_ETL_Python\\\\ETL DATASET\\\\Dataset_ ventas\\\\2015\\\\Marzo\\\\2015Marzo.xlsx',\n",
       " 'C:\\\\Users\\\\LUIGGI\\\\Desktop\\\\Curso_ETL_Python\\\\ETL DATASET\\\\Dataset_ ventas\\\\2015\\\\Mayo\\\\2015Mayo.xlsx',\n",
       " 'C:\\\\Users\\\\LUIGGI\\\\Desktop\\\\Curso_ETL_Python\\\\ETL DATASET\\\\Dataset_ ventas\\\\2015\\\\Noviembre\\\\2015Noviembre.xlsx',\n",
       " 'C:\\\\Users\\\\LUIGGI\\\\Desktop\\\\Curso_ETL_Python\\\\ETL DATASET\\\\Dataset_ ventas\\\\2015\\\\Octubre\\\\2015Octubre.xlsx',\n",
       " 'C:\\\\Users\\\\LUIGGI\\\\Desktop\\\\Curso_ETL_Python\\\\ETL DATASET\\\\Dataset_ ventas\\\\2015\\\\Septiembre\\\\2015Septiembre.xlsx',\n",
       " 'C:\\\\Users\\\\LUIGGI\\\\Desktop\\\\Curso_ETL_Python\\\\ETL DATASET\\\\Dataset_ ventas\\\\2016\\\\Abril\\\\2016Abril.xlsx',\n",
       " 'C:\\\\Users\\\\LUIGGI\\\\Desktop\\\\Curso_ETL_Python\\\\ETL DATASET\\\\Dataset_ ventas\\\\2016\\\\Agosto\\\\2016Agosto.xlsx',\n",
       " 'C:\\\\Users\\\\LUIGGI\\\\Desktop\\\\Curso_ETL_Python\\\\ETL DATASET\\\\Dataset_ ventas\\\\2016\\\\Diciembre\\\\2016Diciembre.xlsx',\n",
       " 'C:\\\\Users\\\\LUIGGI\\\\Desktop\\\\Curso_ETL_Python\\\\ETL DATASET\\\\Dataset_ ventas\\\\2016\\\\Enero\\\\2016Enero.xlsx',\n",
       " 'C:\\\\Users\\\\LUIGGI\\\\Desktop\\\\Curso_ETL_Python\\\\ETL DATASET\\\\Dataset_ ventas\\\\2016\\\\Febrero\\\\2016Febrero.xlsx',\n",
       " 'C:\\\\Users\\\\LUIGGI\\\\Desktop\\\\Curso_ETL_Python\\\\ETL DATASET\\\\Dataset_ ventas\\\\2016\\\\Julio\\\\2016Julio.xlsx',\n",
       " 'C:\\\\Users\\\\LUIGGI\\\\Desktop\\\\Curso_ETL_Python\\\\ETL DATASET\\\\Dataset_ ventas\\\\2016\\\\Junio\\\\2016Junio.xlsx',\n",
       " 'C:\\\\Users\\\\LUIGGI\\\\Desktop\\\\Curso_ETL_Python\\\\ETL DATASET\\\\Dataset_ ventas\\\\2016\\\\Marzo\\\\2016Marzo.xlsx',\n",
       " 'C:\\\\Users\\\\LUIGGI\\\\Desktop\\\\Curso_ETL_Python\\\\ETL DATASET\\\\Dataset_ ventas\\\\2016\\\\Mayo\\\\2016Mayo.xlsx',\n",
       " 'C:\\\\Users\\\\LUIGGI\\\\Desktop\\\\Curso_ETL_Python\\\\ETL DATASET\\\\Dataset_ ventas\\\\2016\\\\Noviembre\\\\2016Noviembre.xlsx',\n",
       " 'C:\\\\Users\\\\LUIGGI\\\\Desktop\\\\Curso_ETL_Python\\\\ETL DATASET\\\\Dataset_ ventas\\\\2016\\\\Octubre\\\\2016Octubre.xlsx',\n",
       " 'C:\\\\Users\\\\LUIGGI\\\\Desktop\\\\Curso_ETL_Python\\\\ETL DATASET\\\\Dataset_ ventas\\\\2016\\\\Septiembre\\\\2016Septiembre.xlsx',\n",
       " 'C:\\\\Users\\\\LUIGGI\\\\Desktop\\\\Curso_ETL_Python\\\\ETL DATASET\\\\Dataset_ ventas\\\\2017\\\\Abril\\\\2017Abril.xlsx',\n",
       " 'C:\\\\Users\\\\LUIGGI\\\\Desktop\\\\Curso_ETL_Python\\\\ETL DATASET\\\\Dataset_ ventas\\\\2017\\\\Agosto\\\\2017Agosto.xlsx',\n",
       " 'C:\\\\Users\\\\LUIGGI\\\\Desktop\\\\Curso_ETL_Python\\\\ETL DATASET\\\\Dataset_ ventas\\\\2017\\\\Diciembre\\\\2017Diciembre.xlsx',\n",
       " 'C:\\\\Users\\\\LUIGGI\\\\Desktop\\\\Curso_ETL_Python\\\\ETL DATASET\\\\Dataset_ ventas\\\\2017\\\\Enero\\\\2017Enero.xlsx',\n",
       " 'C:\\\\Users\\\\LUIGGI\\\\Desktop\\\\Curso_ETL_Python\\\\ETL DATASET\\\\Dataset_ ventas\\\\2017\\\\Febrero\\\\2017Febrero.xlsx',\n",
       " 'C:\\\\Users\\\\LUIGGI\\\\Desktop\\\\Curso_ETL_Python\\\\ETL DATASET\\\\Dataset_ ventas\\\\2017\\\\Julio\\\\2017Julio.xlsx',\n",
       " 'C:\\\\Users\\\\LUIGGI\\\\Desktop\\\\Curso_ETL_Python\\\\ETL DATASET\\\\Dataset_ ventas\\\\2017\\\\Junio\\\\2017Junio.xlsx',\n",
       " 'C:\\\\Users\\\\LUIGGI\\\\Desktop\\\\Curso_ETL_Python\\\\ETL DATASET\\\\Dataset_ ventas\\\\2017\\\\Marzo\\\\2017Marzo.xlsx',\n",
       " 'C:\\\\Users\\\\LUIGGI\\\\Desktop\\\\Curso_ETL_Python\\\\ETL DATASET\\\\Dataset_ ventas\\\\2017\\\\Mayo\\\\2017Mayo.xlsx',\n",
       " 'C:\\\\Users\\\\LUIGGI\\\\Desktop\\\\Curso_ETL_Python\\\\ETL DATASET\\\\Dataset_ ventas\\\\2017\\\\Noviembre\\\\2017Noviembre.xlsx',\n",
       " 'C:\\\\Users\\\\LUIGGI\\\\Desktop\\\\Curso_ETL_Python\\\\ETL DATASET\\\\Dataset_ ventas\\\\2017\\\\Octubre\\\\2017Octubre.xlsx',\n",
       " 'C:\\\\Users\\\\LUIGGI\\\\Desktop\\\\Curso_ETL_Python\\\\ETL DATASET\\\\Dataset_ ventas\\\\2017\\\\Septiembre\\\\2017Septiembre.xlsx']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archivo_por_procesar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6e805fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:03<00:00, 12.25it/s]\n",
      "C:\\Users\\LUIGGI\\AppData\\Local\\Temp\\ipykernel_36012\\1899574132.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  archivo = archivo.append(archivo_nuevo)\n"
     ]
    }
   ],
   "source": [
    "for x in tqdm.tqdm(archivo_por_procesar):\n",
    "    tmp = pd.read_excel(x)\n",
    "    procesado.append( tmp )\n",
    "    archivo_procesado.append(x)\n",
    "    \n",
    "df = pd.concat(procesado, axis = 0) \n",
    "df.to_excel(\"Consolidado.xlsx\", index = False)\n",
    "\n",
    "archivo_nuevo = pd.DataFrame(archivo_procesado, columns=[\"Archivo\"] )  \n",
    "archivo = archivo.append(archivo_nuevo)\n",
    "archivo.to_excel(\"Archivo_procesado.xlsx\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bf42fd",
   "metadata": {},
   "source": [
    "# Ejercicio ETL 3 Avanzado-Carga SQL- WEB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b364a2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: pyodbc in d:\\bcp\\algortimo\\curso_etl_python\\lib\\site-packages (4.0.35)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyodbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "780ab32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carga desde SQL\n",
    "import pyodbc\n",
    "cnxn = pyodbc.connect(driver='{SQL Server Native Client 11.0}',\n",
    "                      host='DESKTOP-LPN6KNV\\MSQL', database='CLASE'\n",
    "                      ,trusted_connection='yes') #, user=uname, password=pword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bda1cb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   COD_CAMION   MARCA  MODELO  ANNO  PESO_CARGA      PATENTE  VALOR\n",
      "0        1000  susuki  baleno  1995          45      pi-1516  50000\n",
      "1        2000   Mazda     cx3  2021          30      pi-pucp  28000\n",
      "2        3000   TESLA    T100  2022          25  pi-elonmusk  50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LUIGGI\\AppData\\Local\\Temp\\ipykernel_21712\\2087840577.py:2: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data = pd.read_sql(sql, cnxn)\n"
     ]
    }
   ],
   "source": [
    "sql = \"SELECT * FROM CAMIONES\"\n",
    "data = pd.read_sql(sql, cnxn)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c9a91532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>1/22/20</th>\n",
       "      <th>1/23/20</th>\n",
       "      <th>1/24/20</th>\n",
       "      <th>1/25/20</th>\n",
       "      <th>1/26/20</th>\n",
       "      <th>1/27/20</th>\n",
       "      <th>...</th>\n",
       "      <th>12/26/22</th>\n",
       "      <th>12/27/22</th>\n",
       "      <th>12/28/22</th>\n",
       "      <th>12/29/22</th>\n",
       "      <th>12/30/22</th>\n",
       "      <th>12/31/22</th>\n",
       "      <th>1/1/23</th>\n",
       "      <th>1/2/23</th>\n",
       "      <th>1/3/23</th>\n",
       "      <th>1/4/23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.93911</td>\n",
       "      <td>67.709953</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>207438</td>\n",
       "      <td>207460</td>\n",
       "      <td>207493</td>\n",
       "      <td>207511</td>\n",
       "      <td>207550</td>\n",
       "      <td>207559</td>\n",
       "      <td>207616</td>\n",
       "      <td>207627</td>\n",
       "      <td>207654</td>\n",
       "      <td>207715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Albania</td>\n",
       "      <td>41.15330</td>\n",
       "      <td>20.168300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>333751</td>\n",
       "      <td>333751</td>\n",
       "      <td>333776</td>\n",
       "      <td>333776</td>\n",
       "      <td>333806</td>\n",
       "      <td>333806</td>\n",
       "      <td>333811</td>\n",
       "      <td>333812</td>\n",
       "      <td>333812</td>\n",
       "      <td>333818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>28.03390</td>\n",
       "      <td>1.659600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>271198</td>\n",
       "      <td>271202</td>\n",
       "      <td>271208</td>\n",
       "      <td>271217</td>\n",
       "      <td>271223</td>\n",
       "      <td>271228</td>\n",
       "      <td>271229</td>\n",
       "      <td>271229</td>\n",
       "      <td>271230</td>\n",
       "      <td>271236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>42.50630</td>\n",
       "      <td>1.521800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>47686</td>\n",
       "      <td>47686</td>\n",
       "      <td>47751</td>\n",
       "      <td>47751</td>\n",
       "      <td>47751</td>\n",
       "      <td>47751</td>\n",
       "      <td>47751</td>\n",
       "      <td>47751</td>\n",
       "      <td>47751</td>\n",
       "      <td>47751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Angola</td>\n",
       "      <td>-11.20270</td>\n",
       "      <td>17.873900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>104973</td>\n",
       "      <td>105095</td>\n",
       "      <td>105095</td>\n",
       "      <td>105095</td>\n",
       "      <td>105095</td>\n",
       "      <td>105095</td>\n",
       "      <td>105095</td>\n",
       "      <td>105095</td>\n",
       "      <td>105095</td>\n",
       "      <td>105095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1083 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province/State Country/Region       Lat       Long  1/22/20  1/23/20  \\\n",
       "0            NaN    Afghanistan  33.93911  67.709953        0        0   \n",
       "1            NaN        Albania  41.15330  20.168300        0        0   \n",
       "2            NaN        Algeria  28.03390   1.659600        0        0   \n",
       "3            NaN        Andorra  42.50630   1.521800        0        0   \n",
       "4            NaN         Angola -11.20270  17.873900        0        0   \n",
       "\n",
       "   1/24/20  1/25/20  1/26/20  1/27/20  ...  12/26/22  12/27/22  12/28/22  \\\n",
       "0        0        0        0        0  ...    207438    207460    207493   \n",
       "1        0        0        0        0  ...    333751    333751    333776   \n",
       "2        0        0        0        0  ...    271198    271202    271208   \n",
       "3        0        0        0        0  ...     47686     47686     47751   \n",
       "4        0        0        0        0  ...    104973    105095    105095   \n",
       "\n",
       "   12/29/22  12/30/22  12/31/22  1/1/23  1/2/23  1/3/23  1/4/23  \n",
       "0    207511    207550    207559  207616  207627  207654  207715  \n",
       "1    333776    333806    333806  333811  333812  333812  333818  \n",
       "2    271217    271223    271228  271229  271229  271230  271236  \n",
       "3     47751     47751     47751   47751   47751   47751   47751  \n",
       "4    105095    105095    105095  105095  105095  105095  105095  \n",
       "\n",
       "[5 rows x 1083 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Carga desde WEB\n",
    "#Exploremos el siguiente link\n",
    "#https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series\n",
    "\n",
    "#importemos la data directamente\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv\")\n",
    "\n",
    "#importamos la data \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "54433882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fecha:  2023-01-05 22:12:29\n",
      "La temperatura en Peru: 21 °C\n",
      "La sesacion termica: 21 °C\n",
      "Fecha:  2023-01-05 22:12:40\n",
      "La temperatura en Peru: 21 °C\n",
      "La sesacion termica: 21 °C\n",
      "Fecha:  2023-01-05 22:12:50\n",
      "La temperatura en Peru: 21 °C\n",
      "La sesacion termica: 21 °C\n",
      "Fecha:  2023-01-05 22:13:00\n",
      "La temperatura en Peru: 21 °C\n",
      "La sesacion termica: 21 °C\n",
      "Fecha:  2023-01-05 22:13:11\n",
      "La temperatura en Peru: 21 °C\n",
      "La sesacion termica: 21 °C\n",
      "Fecha:  2023-01-05 22:13:21\n",
      "La temperatura en Peru: 21 °C\n",
      "La sesacion termica: 21 °C\n",
      "Fecha:  2023-01-05 22:13:31\n",
      "La temperatura en Peru: 21 °C\n",
      "La sesacion termica: 21 °C\n",
      "Fecha:  2023-01-05 22:13:42\n",
      "La temperatura en Peru: 21 °C\n",
      "La sesacion termica: 21 °C\n",
      "Fecha:  2023-01-05 22:13:52\n",
      "La temperatura en Peru: 21 °C\n",
      "La sesacion termica: 21 °C\n",
      "Fecha:  2023-01-05 22:14:02\n",
      "La temperatura en Peru: 21 °C\n",
      "La sesacion termica: 21 °C\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Temperatura</th>\n",
       "      <th>Sensacion termica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-05 22:12:29</td>\n",
       "      <td>21 °C</td>\n",
       "      <td>21 °C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-05 22:12:40</td>\n",
       "      <td>21 °C</td>\n",
       "      <td>21 °C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-05 22:12:50</td>\n",
       "      <td>21 °C</td>\n",
       "      <td>21 °C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-05 22:13:00</td>\n",
       "      <td>21 °C</td>\n",
       "      <td>21 °C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-05 22:13:11</td>\n",
       "      <td>21 °C</td>\n",
       "      <td>21 °C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-05 22:13:21</td>\n",
       "      <td>21 °C</td>\n",
       "      <td>21 °C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-05 22:13:31</td>\n",
       "      <td>21 °C</td>\n",
       "      <td>21 °C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-05 22:13:42</td>\n",
       "      <td>21 °C</td>\n",
       "      <td>21 °C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-05 22:13:52</td>\n",
       "      <td>21 °C</td>\n",
       "      <td>21 °C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-05 22:14:02</td>\n",
       "      <td>21 °C</td>\n",
       "      <td>21 °C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Fecha Temperatura Sensacion termica\n",
       "0  2023-01-05 22:12:29       21 °C             21 °C\n",
       "0  2023-01-05 22:12:40       21 °C             21 °C\n",
       "0  2023-01-05 22:12:50       21 °C             21 °C\n",
       "0  2023-01-05 22:13:00       21 °C             21 °C\n",
       "0  2023-01-05 22:13:11       21 °C             21 °C\n",
       "0  2023-01-05 22:13:21       21 °C             21 °C\n",
       "0  2023-01-05 22:13:31       21 °C             21 °C\n",
       "0  2023-01-05 22:13:42       21 °C             21 °C\n",
       "0  2023-01-05 22:13:52       21 °C             21 °C\n",
       "0  2023-01-05 22:14:02       21 °C             21 °C"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importamos las librerias\n",
    "!pip install requests\n",
    "!pip install BeautifulSoup4\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "df = pd.DataFrame()\n",
    "# Creamos el Bucle infinito\n",
    "i = 0\n",
    "while i<10:\n",
    "    # Capturamos la url \n",
    "    url = \"https://www.timeanddate.com/weather/peru/lima\"\n",
    "\n",
    "    # Capturamos el hml de la pagina web y creamos un objeto Response\n",
    "    r  = requests.get(url)\n",
    "    data = r.text\n",
    "\n",
    "    # Creamos el objeto soup y le pasamos lo capturado con request\n",
    "    soup = BeautifulSoup(data, 'lxml')\n",
    "\n",
    "    # Buscamos el div para sacar los grados\n",
    "    temp = soup.find_all('div', class_=\"h2\")\n",
    "\n",
    "    # Buscamos el div para sacar la sensacion termica\n",
    "    sTerm = soup.find_all('div', class_=\"clear\")\n",
    "    #Calculamos la fecha del dia de hoy\n",
    "    fecha = str(datetime.datetime.today())[0:19]\n",
    "        # Con [0] saco el primer elemento y con [1] el segundo\n",
    "    print(\"Fecha: \", str(datetime.datetime.today())[0:19])\n",
    "    print(\"La temperatura en Peru: \" + temp[0].text)\n",
    "    print(\"La sesacion termica: \" + sTerm[1].text)\n",
    "    #unimos las bases de datos\n",
    "    df = pd.concat([df , pd.DataFrame([[fecha ,temp[0].text,sTerm[1].text]], columns=[\"Fecha\", \"Temperatura\", \"Sensacion termica\"])])\n",
    "    # Tiempo en segundos para ejecutarse nuevamente\n",
    "    time.sleep(10)\n",
    "\n",
    "    i +=1\n",
    "df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad4e17c",
   "metadata": {},
   "source": [
    "## TRABAJO FINAL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d58a46bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realizamos un loop por año y mes\n",
    "#!pip install xlsxwriter\n",
    "#Codigo Generador de datos\n",
    "## Este codigo genera el archivo base donde van a trabajar , les dejo el codigo para que lo tengan\n",
    "path = r'C:\\Users\\LUIGGI\\Desktop\\Curso_ETL_Python\\ETL DATASET\\Tarea carga'\n",
    "df = pd.read_excel(files[2])\n",
    "for y in year:\n",
    "    if not os.path.exists(path+\"\\\\\"+str(y)):\n",
    "            os.mkdir(path+\"\\\\\"+str(y))\n",
    "    writer = pd.ExcelWriter(path+\"\\\\\"+str(y)+\"\\\\\"+'anual.xlsx', engine='xlsxwriter')\n",
    "    for m in month:\n",
    "        tmp_csv = df[(df['Order Date'].dt.year==y) & (df['Order Date'].dt.month==m)&  (df['Data_origen']==0)  ]\n",
    "        tmp_excel = df[(df['Order Date'].dt.year==y) & (df['Order Date'].dt.month==m)&  (df['Data_origen']==1)  ]\n",
    "        #Si la ruta no existe la creara\n",
    "        tmp_excel.to_excel( writer,sheet_name = dic.get(m),index=False)\n",
    "        tmp_csv.to_csv(path+\"\\\\\"+str(y)+\"\\\\\"+dic.get(m)+\".csv\",index=False)\n",
    "    writer.close()\n",
    "    \n",
    "##### Solo cambiar el path del codigo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "186a1c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tips para realizar la tarea\n",
    "path = r'C:\\Users\\LUIGGI\\Desktop\\Curso_ETL_Python\\ETL DATASET\\Tarea carga'\n",
    "#pista utilice estos codigos para ver los xlsx y los csv , debe utilizar loops para cargar los archivos\n",
    "flujo_excel = glob.glob(f'{path}/*/*.xlsx', recursive=True)\n",
    "flujo_csv =glob.glob(f'{path}/*/*.csv', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "989d0f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#para el flujo csv\n",
    "# Creamos una lista en blanco para cargar los datasets\n",
    "li = []\n",
    "# Realizaremos un loop sobre cada archivo, lo leeremos y lo juntaremos.\n",
    "\n",
    "for f in flujo_csv:\n",
    "    # Leemos el archivo\n",
    "    temp_df = pd.read_csv(f ,sep=',')\n",
    "    # agregamos a la lista los dataframes\n",
    "    li.append(temp_df)\n",
    "    #print(f'Dataframe creado exitosamente para {f} con un tamañao {temp_df.shape}')\n",
    "\n",
    "# Uniremos todos los dataframe en uno\n",
    "df_csv = pd.concat(li, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e839ba2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flujo Excel\n",
    "li = []\n",
    "# Realizaremos un loop sobre cada archivo, lo leeremos y lo juntaremos.\n",
    "for f in flujo_excel:\n",
    "    # Leemos el archivo\n",
    "    wb = openpyxl.load_workbook(f)\n",
    "    #leer las hojas\n",
    "    hojas_Excel = wb.sheetnames\n",
    "    # creear un loop que entre y jale la informacion de cada pestaña\n",
    "    df_Excel = []\n",
    "    for hoja in hojas_Excel:\n",
    "        tmp = pd.read_excel(f,sheet_name = hoja ) \n",
    "        df_Excel.append(temp_df)\n",
    "    df_excel_consolidado = pd.concat(df_Excel, axis=0)\n",
    "\n",
    "    # agregamos a la lista los dataframes\n",
    "    li.append(df_excel_consolidado)\n",
    "    #print(f'Dataframe creado exitosamente para {f} con un tamañao {temp_df.shape}')\n",
    "\n",
    "# Uniremos todos los dataframe en uno\n",
    "df_Excel = pd.concat(li, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42a0204c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LUIGGI\\AppData\\Local\\Temp\\ipykernel_10860\\3028009854.py:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_final = df_Excel.append(df_csv)\n"
     ]
    }
   ],
   "source": [
    "#Finalmente consolido tanto el excel como el csv\n",
    "\n",
    "df_final = df_Excel.append(df_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dc50e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(\"datos_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6aa36c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Noviembre', 'Junio', 'Octubre', 'Abril', 'Diciembre', 'Mayo', 'Agosto', 'Julio', 'Septiembre', 'Enero', 'Marzo', 'Febrero']\n"
     ]
    }
   ],
   "source": [
    "#tips 2 este codigo permite visualizar las pestañas de cada archivo excel, se debe realizar un loop sobre cada archivo excel\n",
    "import openpyxl\n",
    "wb = openpyxl.load_workbook(path +'\\\\2014\\\\anual.xlsx')\n",
    "print(wb.sheetnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c530016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Row ID</th>\n",
       "      <th>Order ID</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Ship Date</th>\n",
       "      <th>Ship Mode</th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>Segment</th>\n",
       "      <th>Country</th>\n",
       "      <th>City</th>\n",
       "      <th>...</th>\n",
       "      <th>Region</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Sub-Category</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Profit</th>\n",
       "      <th>Data_origen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79</td>\n",
       "      <td>US-2014-147606</td>\n",
       "      <td>2014-11-26</td>\n",
       "      <td>2014-12-01</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>JE-15745</td>\n",
       "      <td>Joel Eaton</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Houston</td>\n",
       "      <td>...</td>\n",
       "      <td>Central</td>\n",
       "      <td>FUR-FU-10003194</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Furnishings</td>\n",
       "      <td>Eldon Expressions Desk Accessory, Wood Pencil ...</td>\n",
       "      <td>19.30</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-14.4750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>183</td>\n",
       "      <td>CA-2014-158274</td>\n",
       "      <td>2014-11-19</td>\n",
       "      <td>2014-11-24</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>RM-19675</td>\n",
       "      <td>Robert Marley</td>\n",
       "      <td>Home Office</td>\n",
       "      <td>United States</td>\n",
       "      <td>Monroe</td>\n",
       "      <td>...</td>\n",
       "      <td>South</td>\n",
       "      <td>TEC-PH-10003273</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Phones</td>\n",
       "      <td>AT&amp;T TR1909W</td>\n",
       "      <td>503.96</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131.0296</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>184</td>\n",
       "      <td>CA-2014-158274</td>\n",
       "      <td>2014-11-19</td>\n",
       "      <td>2014-11-24</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>RM-19675</td>\n",
       "      <td>Robert Marley</td>\n",
       "      <td>Home Office</td>\n",
       "      <td>United States</td>\n",
       "      <td>Monroe</td>\n",
       "      <td>...</td>\n",
       "      <td>South</td>\n",
       "      <td>TEC-PH-10004896</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Phones</td>\n",
       "      <td>Nokia Lumia 521 (T-Mobile)</td>\n",
       "      <td>149.95</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.9860</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>319</td>\n",
       "      <td>CA-2014-164973</td>\n",
       "      <td>2014-11-04</td>\n",
       "      <td>2014-11-09</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>NM-18445</td>\n",
       "      <td>Nathan Mautz</td>\n",
       "      <td>Home Office</td>\n",
       "      <td>United States</td>\n",
       "      <td>New York City</td>\n",
       "      <td>...</td>\n",
       "      <td>East</td>\n",
       "      <td>TEC-MA-10002927</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Machines</td>\n",
       "      <td>Canon imageCLASS MF7460 Monochrome Digital Las...</td>\n",
       "      <td>3991.98</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1995.9900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>320</td>\n",
       "      <td>CA-2014-164973</td>\n",
       "      <td>2014-11-04</td>\n",
       "      <td>2014-11-09</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>NM-18445</td>\n",
       "      <td>Nathan Mautz</td>\n",
       "      <td>Home Office</td>\n",
       "      <td>United States</td>\n",
       "      <td>New York City</td>\n",
       "      <td>...</td>\n",
       "      <td>East</td>\n",
       "      <td>TEC-PH-10004093</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Phones</td>\n",
       "      <td>Panasonic Kx-TS550</td>\n",
       "      <td>275.94</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0226</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Row ID        Order ID Order Date  Ship Date       Ship Mode Customer ID  \\\n",
       "0      79  US-2014-147606 2014-11-26 2014-12-01    Second Class    JE-15745   \n",
       "1     183  CA-2014-158274 2014-11-19 2014-11-24    Second Class    RM-19675   \n",
       "2     184  CA-2014-158274 2014-11-19 2014-11-24    Second Class    RM-19675   \n",
       "3     319  CA-2014-164973 2014-11-04 2014-11-09  Standard Class    NM-18445   \n",
       "4     320  CA-2014-164973 2014-11-04 2014-11-09  Standard Class    NM-18445   \n",
       "\n",
       "   Customer Name      Segment        Country           City  ...   Region  \\\n",
       "0     Joel Eaton     Consumer  United States        Houston  ...  Central   \n",
       "1  Robert Marley  Home Office  United States         Monroe  ...    South   \n",
       "2  Robert Marley  Home Office  United States         Monroe  ...    South   \n",
       "3   Nathan Mautz  Home Office  United States  New York City  ...     East   \n",
       "4   Nathan Mautz  Home Office  United States  New York City  ...     East   \n",
       "\n",
       "        Product ID    Category Sub-Category  \\\n",
       "0  FUR-FU-10003194   Furniture  Furnishings   \n",
       "1  TEC-PH-10003273  Technology       Phones   \n",
       "2  TEC-PH-10004896  Technology       Phones   \n",
       "3  TEC-MA-10002927  Technology     Machines   \n",
       "4  TEC-PH-10004093  Technology       Phones   \n",
       "\n",
       "                                        Product Name    Sales Quantity  \\\n",
       "0  Eldon Expressions Desk Accessory, Wood Pencil ...    19.30        5   \n",
       "1                                       AT&T TR1909W   503.96        4   \n",
       "2                         Nokia Lumia 521 (T-Mobile)   149.95        5   \n",
       "3  Canon imageCLASS MF7460 Monochrome Digital Las...  3991.98        2   \n",
       "4                                 Panasonic Kx-TS550   275.94        6   \n",
       "\n",
       "   Discount     Profit  Data_origen  \n",
       "0       0.6   -14.4750            1  \n",
       "1       0.0   131.0296            1  \n",
       "2       0.0    41.9860            1  \n",
       "3       0.0  1995.9900            1  \n",
       "4       0.0    80.0226            1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tips 3\n",
    "# Para cargar una hoja especifica de un excel se debe realizar lo siguiente\n",
    "tmp = pd.read_excel(path +'\\\\2014\\\\anual.xlsx',sheet_name = 'Noviembre' ) \n",
    "tmp.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf2fd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Debe cargar todos los archivos tanto en csv y en excel y unirlos todo en un solo file\n",
    "#Deben guardar el archivo final en la carpeta con el nombre consolidado.xlsx\n",
    "\n",
    "#enviar el codigo final en un word con fotos del proceso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ae75d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tips para realizar la tarea\n",
    "path = r'C:\\Users\\LUIGGI\\Desktop\\Curso_ETL_Python\\ETL DATASET\\Tarea carga'\n",
    "#pista utilice estos codigos para ver los xlsx y los csv , debe utilizar loops para cargar los archivos\n",
    "flujo_excel = glob.glob(f'{path}/*/*.xlsx', recursive=True)\n",
    "flujo_csv =glob.glob(f'{path}/*/*.csv', recursive=True)\n",
    "\n",
    "#para el flujo csv\n",
    "# Creamos una lista en blanco para cargar los datasets\n",
    "li = []\n",
    "# Realizaremos un loop sobre cada archivo, lo leeremos y lo juntaremos.\n",
    "\n",
    "for f in flujo_csv:\n",
    "    # Leemos el archivo\n",
    "    temp_df = pd.read_csv(f ,sep=',')\n",
    "    # agregamos a la lista los dataframes\n",
    "    li.append(temp_df)\n",
    "    #print(f'Dataframe creado exitosamente para {f} con un tamañao {temp_df.shape}')\n",
    "\n",
    "# Uniremos todos los dataframe en uno\n",
    "df_csv = pd.concat(li, axis=0)\n",
    "\n",
    "#Finalmente consolido tanto el excel como el csv\n",
    "\n",
    "df_final = df_Excel.append(df_csv)\n",
    "\n",
    "df_final.to_csv(\"datos_final\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
