{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf93d8bb",
   "metadata": {},
   "source": [
    "# Ejercicio ETL 1 basic-Carga\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bd24cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#algunas librerias importantes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83ea785b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Diciembre_2022.csv', 'Enero_2023.csv', 'Febrero_2023.csv', 'Marzo_2023.csv', 'Noviembre_2022.csv']\n"
     ]
    }
   ],
   "source": [
    "# Importando las librerias\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "# Seteamos el directorio a buscar los archivos\n",
    "#D:\\ANALYTIC_PYTHON\\EntornoPython\\ETL DATASET\\World Cup\n",
    "path = r'D:\\ANALYTIC_PYTHON\\EntornoPython\\ETL DATASET\\World Cup\\Raw'\n",
    "#cambiamos el path\n",
    "os.chdir(path)\n",
    "#\n",
    "files = glob.glob( '*.csv')\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf3933c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe creado exitosamente para Diciembre_2022.csv con un tamañao (24, 6)\n",
      "Dataframe creado exitosamente para Enero_2023.csv con un tamañao (40, 6)\n",
      "Dataframe creado exitosamente para Febrero_2023.csv con un tamañao (40, 6)\n",
      "Dataframe creado exitosamente para Marzo_2023.csv con un tamañao (40, 6)\n",
      "Dataframe creado exitosamente para Noviembre_2022.csv con un tamañao (40, 6)\n",
      "(184, 6)\n"
     ]
    }
   ],
   "source": [
    "# Creamos una lista en blanco para cargar los datasets\n",
    "li = []\n",
    "# Realizaremos un loop sobre cada archivo, lo leeremos y lo juntaremos.\n",
    "\n",
    "for f in files:\n",
    "    # Leemos el archivo\n",
    "    temp_df = pd.read_csv(f ,sep=';')\n",
    "    # agregamos a la lista los dataframes\n",
    "    li.append(temp_df)\n",
    "    print(f'Dataframe creado exitosamente para {f} con un tamañao {temp_df.shape}')\n",
    "\n",
    "# Uniremos todos los dataframe en uno\n",
    "df = pd.concat(li, axis=0)\n",
    "print(df.shape)\n",
    "df.head()\n",
    "df.to_csv(r'D:\\ANALYTIC_PYTHON\\EntornoPython\\ETL DATASET\\World Cup\\Consolidado\\Merge1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21639f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pasemos el codigo a un Py\n",
    "#se pasó el codigo desde el pychram\n",
    "#cramos un archivo py llamado ETL1_python.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72314201",
   "metadata": {},
   "source": [
    "# Ejercicio ETL 1 Basic-Carga-Mejorado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d273086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Home</th>\n",
       "      <th>Away</th>\n",
       "      <th>Attendance</th>\n",
       "      <th>Venue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01 December 2022</td>\n",
       "      <td>18:00 (20:30)</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Morocco</td>\n",
       "      <td>43,102</td>\n",
       "      <td>Al Thumama Stadium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01 December 2022</td>\n",
       "      <td>18:00 (20:30)</td>\n",
       "      <td>Croatia</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>43,984</td>\n",
       "      <td>Ahmed bin Ali Stadium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01 December 2022</td>\n",
       "      <td>22:00 (00:30)</td>\n",
       "      <td>Costa Rica</td>\n",
       "      <td>Germany</td>\n",
       "      <td>67,054</td>\n",
       "      <td>Al Bayt Stadium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01 December 2022</td>\n",
       "      <td>22:00 (00:30)</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Spain</td>\n",
       "      <td>44,851</td>\n",
       "      <td>Khalifa International Stadium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02 December 2022</td>\n",
       "      <td>18:00 (20:30)</td>\n",
       "      <td>Korea Republic</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>44,097</td>\n",
       "      <td>Education City Stadium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>02 December 2022</td>\n",
       "      <td>18:00 (20:30)</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>Uruguay</td>\n",
       "      <td>43,443</td>\n",
       "      <td>Al Janoub Stadium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>02 December 2022</td>\n",
       "      <td>22:00 (00:30)</td>\n",
       "      <td>Cameroon</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>85,986</td>\n",
       "      <td>Lusail Iconic Stadium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>02 December 2022</td>\n",
       "      <td>22:00 (00:30)</td>\n",
       "      <td>Serbia</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>41,378</td>\n",
       "      <td>Stadium 974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>03 December 2022</td>\n",
       "      <td>18:00 (20:30)</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>USA</td>\n",
       "      <td>44,846</td>\n",
       "      <td>Khalifa International Stadium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>03 December 2022</td>\n",
       "      <td>22:00 (00:30)</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Australia</td>\n",
       "      <td>45,032</td>\n",
       "      <td>Ahmed bin Ali Stadium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>04 December 2022</td>\n",
       "      <td>18:00 (20:30)</td>\n",
       "      <td>France</td>\n",
       "      <td>Poland</td>\n",
       "      <td>40,989</td>\n",
       "      <td>Al Thumama Stadium (Neutral Site)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>04 December 2022</td>\n",
       "      <td>22:00 (00:30)</td>\n",
       "      <td>England</td>\n",
       "      <td>Senegal</td>\n",
       "      <td>65,985</td>\n",
       "      <td>Al Bayt Stadium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>05 December 2022</td>\n",
       "      <td>18:00 (20:30)</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Croatia</td>\n",
       "      <td>42,523</td>\n",
       "      <td>Al Janoub Stadium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>05 December 2022</td>\n",
       "      <td>22:00 (00:30)</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Korea Republic</td>\n",
       "      <td>43,847</td>\n",
       "      <td>Stadium 974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>06 December 2022</td>\n",
       "      <td>18:00 (20:30)</td>\n",
       "      <td>Morocco</td>\n",
       "      <td>Spain</td>\n",
       "      <td>44,667</td>\n",
       "      <td>Education City Stadium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>06 December 2022</td>\n",
       "      <td>22:00 (00:30)</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>83,720</td>\n",
       "      <td>Lusail Iconic Stadium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>09 December 2022</td>\n",
       "      <td>18:00 (20:30)</td>\n",
       "      <td>Croatia</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>43,893</td>\n",
       "      <td>Education City Stadium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>09 December 2022</td>\n",
       "      <td>22:00 (00:30)</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>88,235</td>\n",
       "      <td>Lusail Iconic Stadium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10 December 2022</td>\n",
       "      <td>18:00 (20:30)</td>\n",
       "      <td>Morocco</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>44,198</td>\n",
       "      <td>Al Thumama Stadium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10 December 2022</td>\n",
       "      <td>22:00 (00:30)</td>\n",
       "      <td>England</td>\n",
       "      <td>France</td>\n",
       "      <td>68,895</td>\n",
       "      <td>Al Bayt Stadium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>13 December 2022</td>\n",
       "      <td>22:00 (00:30)</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Croatia</td>\n",
       "      <td>88,966</td>\n",
       "      <td>Lusail Iconic Stadium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>14 December 2022</td>\n",
       "      <td>22:00 (00:30)</td>\n",
       "      <td>France</td>\n",
       "      <td>Morocco</td>\n",
       "      <td>68,294</td>\n",
       "      <td>Al Bayt Stadium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>17 December 2022</td>\n",
       "      <td>18:00 (20:30)</td>\n",
       "      <td>Croatia</td>\n",
       "      <td>Morocco</td>\n",
       "      <td>44,137</td>\n",
       "      <td>Khalifa International Stadium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>18 December 2022</td>\n",
       "      <td>18:00 (20:30)</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>France</td>\n",
       "      <td>88,966</td>\n",
       "      <td>Lusail Iconic Stadium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Date           Time            Home            Away  \\\n",
       "0   01 December 2022  18:00 (20:30)          Canada         Morocco   \n",
       "1   01 December 2022  18:00 (20:30)         Croatia         Belgium   \n",
       "2   01 December 2022  22:00 (00:30)     Costa Rica          Germany   \n",
       "3   01 December 2022  22:00 (00:30)           Japan           Spain   \n",
       "4   02 December 2022  18:00 (20:30)  Korea Republic        Portugal   \n",
       "5   02 December 2022  18:00 (20:30)           Ghana         Uruguay   \n",
       "6   02 December 2022  22:00 (00:30)        Cameroon          Brazil   \n",
       "7   02 December 2022  22:00 (00:30)          Serbia     Switzerland   \n",
       "8   03 December 2022  18:00 (20:30)     Netherlands             USA   \n",
       "9   03 December 2022  22:00 (00:30)       Argentina       Australia   \n",
       "10  04 December 2022  18:00 (20:30)          France          Poland   \n",
       "11  04 December 2022  22:00 (00:30)         England         Senegal   \n",
       "12  05 December 2022  18:00 (20:30)           Japan         Croatia   \n",
       "13  05 December 2022  22:00 (00:30)          Brazil  Korea Republic   \n",
       "14  06 December 2022  18:00 (20:30)         Morocco           Spain   \n",
       "15  06 December 2022  22:00 (00:30)        Portugal     Switzerland   \n",
       "16  09 December 2022  18:00 (20:30)         Croatia          Brazil   \n",
       "17  09 December 2022  22:00 (00:30)     Netherlands       Argentina   \n",
       "18  10 December 2022  18:00 (20:30)         Morocco        Portugal   \n",
       "19  10 December 2022  22:00 (00:30)         England          France   \n",
       "20  13 December 2022  22:00 (00:30)       Argentina         Croatia   \n",
       "21  14 December 2022  22:00 (00:30)          France         Morocco   \n",
       "22  17 December 2022  18:00 (20:30)         Croatia         Morocco   \n",
       "23  18 December 2022  18:00 (20:30)       Argentina          France   \n",
       "\n",
       "   Attendance                              Venue  \n",
       "0      43,102                 Al Thumama Stadium  \n",
       "1      43,984              Ahmed bin Ali Stadium  \n",
       "2      67,054                    Al Bayt Stadium  \n",
       "3      44,851      Khalifa International Stadium  \n",
       "4      44,097             Education City Stadium  \n",
       "5      43,443                  Al Janoub Stadium  \n",
       "6      85,986              Lusail Iconic Stadium  \n",
       "7      41,378                        Stadium 974  \n",
       "8      44,846      Khalifa International Stadium  \n",
       "9      45,032              Ahmed bin Ali Stadium  \n",
       "10     40,989  Al Thumama Stadium (Neutral Site)  \n",
       "11     65,985                    Al Bayt Stadium  \n",
       "12     42,523                  Al Janoub Stadium  \n",
       "13     43,847                        Stadium 974  \n",
       "14     44,667             Education City Stadium  \n",
       "15     83,720              Lusail Iconic Stadium  \n",
       "16     43,893             Education City Stadium  \n",
       "17     88,235              Lusail Iconic Stadium  \n",
       "18     44,198                 Al Thumama Stadium  \n",
       "19     68,895                    Al Bayt Stadium  \n",
       "20     88,966              Lusail Iconic Stadium  \n",
       "21     68,294                    Al Bayt Stadium  \n",
       "22     44,137      Khalifa International Stadium  \n",
       "23     88,966              Lusail Iconic Stadium  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#crearemos una funcion para leer solo algunas columnas\n",
    "\n",
    "def leer_csv(path=\"\",column_name =[] , sep=';'):\n",
    "    \n",
    "    if len(column_name) == 0:\n",
    "        \n",
    "        df = pd.read_csv(path, sep=';')\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        df = pd.read_csv(path,usecols = column_name, sep=';')\n",
    "        \n",
    "    return df\n",
    "\n",
    "#puede ser asi\n",
    "#leer_csv(path=files[0] ,column_name =[\"Date\", \"Time\", \"Away\"], sep=';')\n",
    "\n",
    "#o puede ser asi\n",
    "leer_csv(path=files[0] ,column_name =[], sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66c1880b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Diciembre_2022.csv', 'Enero_2023.csv', 'Febrero_2023.csv', 'Marzo_2023.csv', 'Noviembre_2022.csv']\n"
     ]
    }
   ],
   "source": [
    "# Importando las librerias\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "# Seteamos el directorio a buscar los archivos\n",
    "path = r'D:\\ANALYTIC_PYTHON\\EntornoPython\\ETL DATASET\\World Cup\\Raw'\n",
    "#cambiamos el path\n",
    "os.chdir(path)\n",
    "# vamos  a buscar todos los archivos que son csv\n",
    "files = glob.glob('*.csv')\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75829d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe creado exitosamente para Diciembre_2022.csv con un tamañao (24, 6)\n",
      "Dataframe creado exitosamente para Enero_2023.csv con un tamañao (40, 6)\n",
      "Dataframe creado exitosamente para Febrero_2023.csv con un tamañao (40, 6)\n",
      "Dataframe creado exitosamente para Marzo_2023.csv con un tamañao (40, 6)\n",
      "Dataframe creado exitosamente para Noviembre_2022.csv con un tamañao (40, 6)\n",
      "(184, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Home</th>\n",
       "      <th>Away</th>\n",
       "      <th>Attendance</th>\n",
       "      <th>Venue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01 December 2022</td>\n",
       "      <td>18:00 (20:30)</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Morocco</td>\n",
       "      <td>43,102</td>\n",
       "      <td>Al Thumama Stadium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01 December 2022</td>\n",
       "      <td>18:00 (20:30)</td>\n",
       "      <td>Croatia</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>43,984</td>\n",
       "      <td>Ahmed bin Ali Stadium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01 December 2022</td>\n",
       "      <td>22:00 (00:30)</td>\n",
       "      <td>Costa Rica</td>\n",
       "      <td>Germany</td>\n",
       "      <td>67,054</td>\n",
       "      <td>Al Bayt Stadium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01 December 2022</td>\n",
       "      <td>22:00 (00:30)</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Spain</td>\n",
       "      <td>44,851</td>\n",
       "      <td>Khalifa International Stadium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02 December 2022</td>\n",
       "      <td>18:00 (20:30)</td>\n",
       "      <td>Korea Republic</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>44,097</td>\n",
       "      <td>Education City Stadium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date           Time            Home      Away Attendance  \\\n",
       "0  01 December 2022  18:00 (20:30)          Canada   Morocco     43,102   \n",
       "1  01 December 2022  18:00 (20:30)         Croatia   Belgium     43,984   \n",
       "2  01 December 2022  22:00 (00:30)     Costa Rica    Germany     67,054   \n",
       "3  01 December 2022  22:00 (00:30)           Japan     Spain     44,851   \n",
       "4  02 December 2022  18:00 (20:30)  Korea Republic  Portugal     44,097   \n",
       "\n",
       "                           Venue  \n",
       "0             Al Thumama Stadium  \n",
       "1          Ahmed bin Ali Stadium  \n",
       "2                Al Bayt Stadium  \n",
       "3  Khalifa International Stadium  \n",
       "4         Education City Stadium  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "# Creamos una lista en blanco para cargar los datasets\n",
    "li = []\n",
    "# Realizaremos un loop sobre cada archivo, lo leeremos y lo juntaremos.\n",
    "\n",
    "path_salida = 'D:/ANALYTIC_PYTHON/EntornoPython/ETL DATASET/World Cup/Procesado/'\n",
    "\n",
    "for f in files:\n",
    "    # Leemos el archivo\n",
    "    temp_df = leer_csv(f ,sep=';')\n",
    "    # agregamos a la lista los dataframes\n",
    "    li.append(temp_df)\n",
    "    \n",
    "    #Moviendo archivos a la capa de Procesado\n",
    "    shutil.move(f, path_salida+f)\n",
    "\n",
    "    print(f'Dataframe creado exitosamente para {f} con un tamañao {temp_df.shape}')\n",
    "\n",
    "# Uniremos todos los dataframe en uno\n",
    "df = pd.concat(li, axis=0)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eca28da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_final = 'D:/ANALYTIC_PYTHON/EntornoPython/ETL DATASET/World Cup/Consolidado/'\n",
    "\n",
    "df.to_csv(path_final+\"MergeFinal.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec676b1",
   "metadata": {},
   "source": [
    "# Ejercicio ETL 2 Intermedio-Carga"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c66661",
   "metadata": {},
   "source": [
    "### CREANDO SEGMENTACION DE LOS DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b4602c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in d:\\analytic_python\\entornopython\\venv\\lib\\site-packages (3.1.1)\n",
      "Requirement already satisfied: et-xmlfile in d:\\analytic_python\\entornopython\\venv\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "['Archivo_procesado.xlsx', 'Consolidado.xlsx', 'Sample - Superstore.xlsx']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Importando las librerias\n",
    "!pip install openpyxl\n",
    "import pandas as pd\n",
    "import glob\n",
    "# Seteamos el directorio a buscar los archivos\n",
    "# vamos  a buscar todos los archivos que son csv\n",
    "\n",
    "#D:\\ANALYTIC_PYTHON\\EntornoPython\\ETL DATASET\n",
    "    \n",
    "path = r'D:\\ANALYTIC_PYTHON\\EntornoPython\\ETL DATASET\\Dataset_ ventas'\n",
    "#cambiamos el path\n",
    "os.chdir(path)\n",
    "files = glob.glob( '*.xlsx')\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "da3d9e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos el archivo\n",
    "df = pd.read_excel(files[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c1347b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recorremos por año y por mes\n",
    "year = df['Order Date'].dt.year.unique()\n",
    "month = df['Order Date'].dt.month.unique()\n",
    "#realizamos el cambio de numero por mes \n",
    "dic = {1:\"Enero\", 2:\"Febrero\", 3:\"Marzo\", 4:\"Abril\", 5:\"Mayo\", 6:\"Junio\", 7:\"Julio\", 8:\"Agosto\", 9:\"Septiembre\", 10:\"Octubre\", 11:\"Noviembre\", 12:\"Diciembre\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d8959e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2016, 2015, 2014, 2017], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7b8eebe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11,  6, 10,  4, 12,  5,  8,  7,  9,  1,  3,  2], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f0903918",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realizamos un loop por año y mes\n",
    "for y in year:\n",
    "    if not os.path.exists(path+\"\\\\\"+str(y)):\n",
    "            os.mkdir(path+\"\\\\\"+str(y))\n",
    "    for m in month:\n",
    "        tmp = df[(df['Order Date'].dt.year==y) & (df['Order Date'].dt.month==m) ]\n",
    "        #Si la ruta no existe la creara\n",
    "        if not os.path.exists(path+\"\\\\\"+str(y)+\"\\\\\"+dic.get(m)):\n",
    "            os.mkdir(path+\"\\\\\"+str(y)+\"\\\\\"+dic.get(m))\n",
    "        tmp.to_excel(path+\"\\\\\"+str(y)+\"\\\\\"+dic.get(m)+\"\\\\\"+str(y)+dic.get(m)+\".xlsx\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aca3e36",
   "metadata": {},
   "source": [
    "### Leyendo los datos de la  subcarpetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "feef1b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in d:\\analytic_python\\entornopython\\venv\\lib\\site-packages (4.65.0)\n",
      "Requirement already satisfied: colorama in d:\\analytic_python\\entornopython\\venv\\lib\\site-packages (from tqdm) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm\n",
    "import tqdm\n",
    "path = r'D:\\ANALYTIC_PYTHON\\EntornoPython\\ETL DATASET\\Dataset_ ventas'\n",
    "\n",
    "# Creare una lista para guardar los dataframe\n",
    "procesado = []\n",
    "\n",
    "#creare una lista para guardar los archivos procesados\n",
    "archivo_procesado = []\n",
    "\n",
    "archivo_por_procesar = glob.glob(f'{path}/*/**/*.xlsx', recursive=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ff83967f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2014\\\\Abril\\\\2014Abril.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2014\\\\Agosto\\\\2014Agosto.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2014\\\\Diciembre\\\\2014Diciembre.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2014\\\\Enero\\\\2014Enero.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2014\\\\Febrero\\\\2014Febrero.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2014\\\\Julio\\\\2014Julio.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2014\\\\Junio\\\\2014Junio.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2014\\\\Marzo\\\\2014Marzo.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2014\\\\Mayo\\\\2014Mayo.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2014\\\\Noviembre\\\\2014Noviembre.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2014\\\\Octubre\\\\2014Octubre.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2014\\\\Septiembre\\\\2014Septiembre.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2015\\\\Abril\\\\2015Abril.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2015\\\\Agosto\\\\2015Agosto.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2015\\\\Diciembre\\\\2015Diciembre.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2015\\\\Enero\\\\2015Enero.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2015\\\\Febrero\\\\2015Febrero.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2015\\\\Julio\\\\2015Julio.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2015\\\\Junio\\\\2015Junio.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2015\\\\Marzo\\\\2015Marzo.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2015\\\\Mayo\\\\2015Mayo.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2015\\\\Noviembre\\\\2015Noviembre.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2015\\\\Octubre\\\\2015Octubre.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2015\\\\Septiembre\\\\2015Septiembre.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2016\\\\Abril\\\\2016Abril.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2016\\\\Agosto\\\\2016Agosto.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2016\\\\Diciembre\\\\2016Diciembre.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2016\\\\Enero\\\\2016Enero.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2016\\\\Febrero\\\\2016Febrero.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2016\\\\Julio\\\\2016Julio.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2016\\\\Junio\\\\2016Junio.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2016\\\\Marzo\\\\2016Marzo.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2016\\\\Mayo\\\\2016Mayo.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2016\\\\Noviembre\\\\2016Noviembre.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2016\\\\Octubre\\\\2016Octubre.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2016\\\\Septiembre\\\\2016Septiembre.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2017\\\\Abril\\\\2017Abril.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2017\\\\Agosto\\\\2017Agosto.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2017\\\\Diciembre\\\\2017Diciembre.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2017\\\\Enero\\\\2017Enero.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2017\\\\Febrero\\\\2017Febrero.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2017\\\\Julio\\\\2017Julio.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2017\\\\Junio\\\\2017Junio.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2017\\\\Marzo\\\\2017Marzo.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2017\\\\Mayo\\\\2017Mayo.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2017\\\\Noviembre\\\\2017Noviembre.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2017\\\\Octubre\\\\2017Octubre.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2017\\\\Septiembre\\\\2017Septiembre.xlsx']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mostrar los archivos encontrados\n",
    "archivo_por_procesar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "810b5cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Archivo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Archivo]\n",
       "Index: []"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Leer\n",
    "archivo = pd.read_excel(\"Archivo_procesado.xlsx\")\n",
    "archivo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "96b40ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validamos los archivos que no se han procesado\n",
    "for x in archivo['Archivo']:\n",
    "    archivo_por_procesar.remove(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "60be9191",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2014\\\\Abril\\\\2014Abril.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2014\\\\Agosto\\\\2014Agosto.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2014\\\\Diciembre\\\\2014Diciembre.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2014\\\\Enero\\\\2014Enero.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2014\\\\Febrero\\\\2014Febrero.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2014\\\\Julio\\\\2014Julio.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2014\\\\Junio\\\\2014Junio.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2014\\\\Marzo\\\\2014Marzo.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2014\\\\Mayo\\\\2014Mayo.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2014\\\\Noviembre\\\\2014Noviembre.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2014\\\\Octubre\\\\2014Octubre.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2014\\\\Septiembre\\\\2014Septiembre.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2015\\\\Abril\\\\2015Abril.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2015\\\\Agosto\\\\2015Agosto.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2015\\\\Diciembre\\\\2015Diciembre.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2015\\\\Enero\\\\2015Enero.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2015\\\\Febrero\\\\2015Febrero.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2015\\\\Julio\\\\2015Julio.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2015\\\\Junio\\\\2015Junio.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2015\\\\Marzo\\\\2015Marzo.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2015\\\\Mayo\\\\2015Mayo.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2015\\\\Noviembre\\\\2015Noviembre.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2015\\\\Octubre\\\\2015Octubre.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2015\\\\Septiembre\\\\2015Septiembre.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2016\\\\Abril\\\\2016Abril.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2016\\\\Agosto\\\\2016Agosto.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2016\\\\Diciembre\\\\2016Diciembre.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2016\\\\Enero\\\\2016Enero.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2016\\\\Febrero\\\\2016Febrero.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2016\\\\Julio\\\\2016Julio.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2016\\\\Junio\\\\2016Junio.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2016\\\\Marzo\\\\2016Marzo.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2016\\\\Mayo\\\\2016Mayo.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2016\\\\Noviembre\\\\2016Noviembre.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2016\\\\Octubre\\\\2016Octubre.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2016\\\\Septiembre\\\\2016Septiembre.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2017\\\\Abril\\\\2017Abril.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2017\\\\Agosto\\\\2017Agosto.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2017\\\\Diciembre\\\\2017Diciembre.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2017\\\\Enero\\\\2017Enero.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2017\\\\Febrero\\\\2017Febrero.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2017\\\\Julio\\\\2017Julio.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2017\\\\Junio\\\\2017Junio.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2017\\\\Marzo\\\\2017Marzo.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2017\\\\Mayo\\\\2017Mayo.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2017\\\\Noviembre\\\\2017Noviembre.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2017\\\\Octubre\\\\2017Octubre.xlsx',\n",
       " 'D:\\\\ANALYTIC_PYTHON\\\\EntornoPython\\\\ETL DATASET\\\\Dataset_ ventas\\\\2017\\\\Septiembre\\\\2017Septiembre.xlsx']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archivo_por_procesar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6e805fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:02<00:00, 16.87it/s]\n",
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_25528\\1899574132.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  archivo = archivo.append(archivo_nuevo)\n"
     ]
    }
   ],
   "source": [
    "for x in tqdm.tqdm(archivo_por_procesar):\n",
    "    tmp = pd.read_excel(x)\n",
    "    procesado.append( tmp )\n",
    "    archivo_procesado.append(x)\n",
    "    \n",
    "df = pd.concat(procesado, axis = 0) \n",
    "df.to_excel(\"Consolidado.xlsx\", index = False)\n",
    "\n",
    "archivo_nuevo = pd.DataFrame(archivo_procesado, columns=[\"Archivo\"] )  \n",
    "archivo = archivo.append(archivo_nuevo)\n",
    "archivo.to_excel(\"Archivo_procesado.xlsx\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bf42fd",
   "metadata": {},
   "source": [
    "# Ejercicio ETL 3 Avanzado-Carga SQL- WEB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b364a2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: pyodbc in d:\\bcp\\algortimo\\curso_etl_python\\lib\\site-packages (4.0.35)\n"
     ]
    }
   ],
   "source": [
    "#!pip install pyodbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "780ab32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carga desde SQL\n",
    "import pyodbc\n",
    "cnxn = pyodbc.connect(driver='{SQL Server Native Client 11.0}',\n",
    "                      host='LAPTOP-J0JK4H2E\\DEVELOPER', database='Northwind'\n",
    "                      ,trusted_connection='yes') #, user=uname, password=pword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bda1cb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   EmployeeID   LastName FirstName                     Title TitleOfCourtesy  \\\n",
      "0           1    Davolio     Nancy      Sales Representative             Ms.   \n",
      "1           2     Fuller    Andrew     Vice President, Sales             Dr.   \n",
      "2           3  Leverling     Janet      Sales Representative             Ms.   \n",
      "3           4    Peacock  Margaret      Sales Representative            Mrs.   \n",
      "4           5   Buchanan    Steven             Sales Manager             Mr.   \n",
      "5           6     Suyama   Michael      Sales Representative             Mr.   \n",
      "6           7       King    Robert      Sales Representative             Mr.   \n",
      "7           8   Callahan     Laura  Inside Sales Coordinator             Ms.   \n",
      "8           9  Dodsworth      Anne      Sales Representative             Ms.   \n",
      "\n",
      "   BirthDate   HireDate                           Address      City Region  \\\n",
      "0 1948-12-08 1992-05-01     507 - 20th Ave. E.\\r\\nApt. 2A   Seattle     WA   \n",
      "1 1952-02-19 1992-08-14                908 W. Capital Way    Tacoma     WA   \n",
      "2 1963-08-30 1992-04-01                722 Moss Bay Blvd.  Kirkland     WA   \n",
      "3 1937-09-19 1993-05-03              4110 Old Redmond Rd.   Redmond     WA   \n",
      "4 1955-03-04 1993-10-17                   14 Garrett Hill    London   None   \n",
      "5 1963-07-02 1993-10-17       Coventry House\\r\\nMiner Rd.    London   None   \n",
      "6 1960-05-29 1994-01-02  Edgeham Hollow\\r\\nWinchester Way    London   None   \n",
      "7 1958-01-09 1994-03-05             4726 - 11th Ave. N.E.   Seattle     WA   \n",
      "8 1966-01-27 1994-11-15                 7 Houndstooth Rd.    London   None   \n",
      "\n",
      "  PostalCode Country       HomePhone Extension  \\\n",
      "0      98122     USA  (206) 555-9857      5467   \n",
      "1      98401     USA  (206) 555-9482      3457   \n",
      "2      98033     USA  (206) 555-3412      3355   \n",
      "3      98052     USA  (206) 555-8122      5176   \n",
      "4    SW1 8JR      UK   (71) 555-4848      3453   \n",
      "5    EC2 7JR      UK   (71) 555-7773       428   \n",
      "6    RG1 9SP      UK   (71) 555-5598       465   \n",
      "7      98105     USA  (206) 555-1189      2344   \n",
      "8    WG2 7LT      UK   (71) 555-4444       452   \n",
      "\n",
      "                                               Photo  \\\n",
      "0  b'\\x15\\x1c/\\x00\\x02\\x00\\x00\\x00\\r\\x00\\x0e\\x00\\...   \n",
      "1  b'\\x15\\x1c/\\x00\\x02\\x00\\x00\\x00\\r\\x00\\x0e\\x00\\...   \n",
      "2  b'\\x15\\x1c/\\x00\\x02\\x00\\x00\\x00\\r\\x00\\x0e\\x00\\...   \n",
      "3  b'\\x15\\x1c/\\x00\\x02\\x00\\x00\\x00\\r\\x00\\x0e\\x00\\...   \n",
      "4  b'\\x15\\x1c/\\x00\\x02\\x00\\x00\\x00\\r\\x00\\x0e\\x00\\...   \n",
      "5  b'\\x15\\x1c/\\x00\\x02\\x00\\x00\\x00\\r\\x00\\x0e\\x00\\...   \n",
      "6  b'\\x15\\x1c/\\x00\\x02\\x00\\x00\\x00\\r\\x00\\x0e\\x00\\...   \n",
      "7  b'\\x15\\x1c/\\x00\\x02\\x00\\x00\\x00\\r\\x00\\x0e\\x00\\...   \n",
      "8  b'\\x15\\x1c/\\x00\\x02\\x00\\x00\\x00\\r\\x00\\x0e\\x00\\...   \n",
      "\n",
      "                                               Notes  ReportsTo  \\\n",
      "0  Education includes a BA in psychology from Col...        2.0   \n",
      "1  Andrew received his BTS commercial in 1974 and...        NaN   \n",
      "2  Janet has a BS degree in chemistry from Boston...        2.0   \n",
      "3  Margaret holds a BA in English literature from...        2.0   \n",
      "4  Steven Buchanan graduated from St. Andrews Uni...        2.0   \n",
      "5  Michael is a graduate of Sussex University (MA...        5.0   \n",
      "6  Robert King served in the Peace Corps and trav...        5.0   \n",
      "7  Laura received a BA in psychology from the Uni...        2.0   \n",
      "8  Anne has a BA degree in English from St. Lawre...        5.0   \n",
      "\n",
      "                                PhotoPath  \n",
      "0    http://accweb/emmployees/davolio.bmp  \n",
      "1     http://accweb/emmployees/fuller.bmp  \n",
      "2  http://accweb/emmployees/leverling.bmp  \n",
      "3    http://accweb/emmployees/peacock.bmp  \n",
      "4   http://accweb/emmployees/buchanan.bmp  \n",
      "5    http://accweb/emmployees/davolio.bmp  \n",
      "6    http://accweb/emmployees/davolio.bmp  \n",
      "7    http://accweb/emmployees/davolio.bmp  \n",
      "8    http://accweb/emmployees/davolio.bmp  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_6536\\3415081633.py:2: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data = pd.read_sql(sql, cnxn)\n"
     ]
    }
   ],
   "source": [
    "sql = \"select * from Employees\"\n",
    "data = pd.read_sql(sql, cnxn)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c9a91532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>1/22/20</th>\n",
       "      <th>1/23/20</th>\n",
       "      <th>1/24/20</th>\n",
       "      <th>1/25/20</th>\n",
       "      <th>1/26/20</th>\n",
       "      <th>1/27/20</th>\n",
       "      <th>...</th>\n",
       "      <th>2/23/23</th>\n",
       "      <th>2/24/23</th>\n",
       "      <th>2/25/23</th>\n",
       "      <th>2/26/23</th>\n",
       "      <th>2/27/23</th>\n",
       "      <th>2/28/23</th>\n",
       "      <th>3/1/23</th>\n",
       "      <th>3/2/23</th>\n",
       "      <th>3/3/23</th>\n",
       "      <th>3/4/23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.93911</td>\n",
       "      <td>67.709953</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>209215</td>\n",
       "      <td>209230</td>\n",
       "      <td>209246</td>\n",
       "      <td>209274</td>\n",
       "      <td>209308</td>\n",
       "      <td>209322</td>\n",
       "      <td>209340</td>\n",
       "      <td>209358</td>\n",
       "      <td>209362</td>\n",
       "      <td>209369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Albania</td>\n",
       "      <td>41.15330</td>\n",
       "      <td>20.168300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>334345</td>\n",
       "      <td>334356</td>\n",
       "      <td>334373</td>\n",
       "      <td>334378</td>\n",
       "      <td>334380</td>\n",
       "      <td>334391</td>\n",
       "      <td>334408</td>\n",
       "      <td>334408</td>\n",
       "      <td>334427</td>\n",
       "      <td>334427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>28.03390</td>\n",
       "      <td>1.659600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>271432</td>\n",
       "      <td>271436</td>\n",
       "      <td>271439</td>\n",
       "      <td>271440</td>\n",
       "      <td>271440</td>\n",
       "      <td>271441</td>\n",
       "      <td>271448</td>\n",
       "      <td>271463</td>\n",
       "      <td>271469</td>\n",
       "      <td>271469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>42.50630</td>\n",
       "      <td>1.521800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>47866</td>\n",
       "      <td>47866</td>\n",
       "      <td>47866</td>\n",
       "      <td>47866</td>\n",
       "      <td>47866</td>\n",
       "      <td>47866</td>\n",
       "      <td>47875</td>\n",
       "      <td>47875</td>\n",
       "      <td>47875</td>\n",
       "      <td>47875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Angola</td>\n",
       "      <td>-11.20270</td>\n",
       "      <td>17.873900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>105205</td>\n",
       "      <td>105205</td>\n",
       "      <td>105205</td>\n",
       "      <td>105205</td>\n",
       "      <td>105255</td>\n",
       "      <td>105255</td>\n",
       "      <td>105277</td>\n",
       "      <td>105277</td>\n",
       "      <td>105277</td>\n",
       "      <td>105277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1142 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province/State Country/Region       Lat       Long  1/22/20  1/23/20  \\\n",
       "0            NaN    Afghanistan  33.93911  67.709953        0        0   \n",
       "1            NaN        Albania  41.15330  20.168300        0        0   \n",
       "2            NaN        Algeria  28.03390   1.659600        0        0   \n",
       "3            NaN        Andorra  42.50630   1.521800        0        0   \n",
       "4            NaN         Angola -11.20270  17.873900        0        0   \n",
       "\n",
       "   1/24/20  1/25/20  1/26/20  1/27/20  ...  2/23/23  2/24/23  2/25/23  \\\n",
       "0        0        0        0        0  ...   209215   209230   209246   \n",
       "1        0        0        0        0  ...   334345   334356   334373   \n",
       "2        0        0        0        0  ...   271432   271436   271439   \n",
       "3        0        0        0        0  ...    47866    47866    47866   \n",
       "4        0        0        0        0  ...   105205   105205   105205   \n",
       "\n",
       "   2/26/23  2/27/23  2/28/23  3/1/23  3/2/23  3/3/23  3/4/23  \n",
       "0   209274   209308   209322  209340  209358  209362  209369  \n",
       "1   334378   334380   334391  334408  334408  334427  334427  \n",
       "2   271440   271440   271441  271448  271463  271469  271469  \n",
       "3    47866    47866    47866   47875   47875   47875   47875  \n",
       "4   105205   105255   105255  105277  105277  105277  105277  \n",
       "\n",
       "[5 rows x 1142 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Carga desde WEB\n",
    "#Exploremos el siguiente link\n",
    "#https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series\n",
    "\n",
    "#importemos la data directamente\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv\")\n",
    "\n",
    "#importamos la data \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "54433882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fecha:  2023-01-05 22:12:29\n",
      "La temperatura en Peru: 21 °C\n",
      "La sesacion termica: 21 °C\n",
      "Fecha:  2023-01-05 22:12:40\n",
      "La temperatura en Peru: 21 °C\n",
      "La sesacion termica: 21 °C\n",
      "Fecha:  2023-01-05 22:12:50\n",
      "La temperatura en Peru: 21 °C\n",
      "La sesacion termica: 21 °C\n",
      "Fecha:  2023-01-05 22:13:00\n",
      "La temperatura en Peru: 21 °C\n",
      "La sesacion termica: 21 °C\n",
      "Fecha:  2023-01-05 22:13:11\n",
      "La temperatura en Peru: 21 °C\n",
      "La sesacion termica: 21 °C\n",
      "Fecha:  2023-01-05 22:13:21\n",
      "La temperatura en Peru: 21 °C\n",
      "La sesacion termica: 21 °C\n",
      "Fecha:  2023-01-05 22:13:31\n",
      "La temperatura en Peru: 21 °C\n",
      "La sesacion termica: 21 °C\n",
      "Fecha:  2023-01-05 22:13:42\n",
      "La temperatura en Peru: 21 °C\n",
      "La sesacion termica: 21 °C\n",
      "Fecha:  2023-01-05 22:13:52\n",
      "La temperatura en Peru: 21 °C\n",
      "La sesacion termica: 21 °C\n",
      "Fecha:  2023-01-05 22:14:02\n",
      "La temperatura en Peru: 21 °C\n",
      "La sesacion termica: 21 °C\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Temperatura</th>\n",
       "      <th>Sensacion termica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-05 22:12:29</td>\n",
       "      <td>21 °C</td>\n",
       "      <td>21 °C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-05 22:12:40</td>\n",
       "      <td>21 °C</td>\n",
       "      <td>21 °C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-05 22:12:50</td>\n",
       "      <td>21 °C</td>\n",
       "      <td>21 °C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-05 22:13:00</td>\n",
       "      <td>21 °C</td>\n",
       "      <td>21 °C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-05 22:13:11</td>\n",
       "      <td>21 °C</td>\n",
       "      <td>21 °C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-05 22:13:21</td>\n",
       "      <td>21 °C</td>\n",
       "      <td>21 °C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-05 22:13:31</td>\n",
       "      <td>21 °C</td>\n",
       "      <td>21 °C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-05 22:13:42</td>\n",
       "      <td>21 °C</td>\n",
       "      <td>21 °C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-05 22:13:52</td>\n",
       "      <td>21 °C</td>\n",
       "      <td>21 °C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-05 22:14:02</td>\n",
       "      <td>21 °C</td>\n",
       "      <td>21 °C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Fecha Temperatura Sensacion termica\n",
       "0  2023-01-05 22:12:29       21 °C             21 °C\n",
       "0  2023-01-05 22:12:40       21 °C             21 °C\n",
       "0  2023-01-05 22:12:50       21 °C             21 °C\n",
       "0  2023-01-05 22:13:00       21 °C             21 °C\n",
       "0  2023-01-05 22:13:11       21 °C             21 °C\n",
       "0  2023-01-05 22:13:21       21 °C             21 °C\n",
       "0  2023-01-05 22:13:31       21 °C             21 °C\n",
       "0  2023-01-05 22:13:42       21 °C             21 °C\n",
       "0  2023-01-05 22:13:52       21 °C             21 °C\n",
       "0  2023-01-05 22:14:02       21 °C             21 °C"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importamos las librerias\n",
    "#!pip install requests\n",
    "#!pip install BeautifulSoup4\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "df = pd.DataFrame()\n",
    "# Creamos el Bucle infinito\n",
    "i = 0\n",
    "while i<10:\n",
    "    # Capturamos la url \n",
    "    url = \"https://www.timeanddate.com/weather/peru/lima\"\n",
    "\n",
    "    # Capturamos el hml de la pagina web y creamos un objeto Response\n",
    "    r  = requests.get(url)\n",
    "    data = r.text\n",
    "\n",
    "    # Creamos el objeto soup y le pasamos lo capturado con request\n",
    "    soup = BeautifulSoup(data, 'lxml')\n",
    "\n",
    "    # Buscamos el div para sacar los grados\n",
    "    temp = soup.find_all('div', class_=\"h2\")\n",
    "\n",
    "    # Buscamos el div para sacar la sensacion termica\n",
    "    sTerm = soup.find_all('div', class_=\"clear\")\n",
    "    #Calculamos la fecha del dia de hoy\n",
    "    fecha = str(datetime.datetime.today())[0:19]\n",
    "        # Con [0] saco el primer elemento y con [1] el segundo\n",
    "    print(\"Fecha: \", str(datetime.datetime.today())[0:19])\n",
    "    print(\"La temperatura en Peru: \" + temp[0].text)\n",
    "    print(\"La sesacion termica: \" + sTerm[1].text)\n",
    "    #unimos las bases de datos\n",
    "    df = pd.concat([df , pd.DataFrame([[fecha ,temp[0].text,sTerm[1].text]], columns=[\"Fecha\", \"Temperatura\", \"Sensacion termica\"])])\n",
    "    # Tiempo en segundos para ejecutarse nuevamente\n",
    "    time.sleep(10)\n",
    "\n",
    "    i +=1\n",
    "df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad4e17c",
   "metadata": {},
   "source": [
    "## TRABAJO FINAL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d58a46bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realizamos un loop por año y mes\n",
    "#pip install xlsxwriter\n",
    "#Codigo Generador de datos\n",
    "## Este codigo genera el archivo base donde van a trabajar , les dejo el codigo para que lo tengan\n",
    "\n",
    "path = r'D:\\ANALYTIC_PYTHON\\EntornoPython\\ETL DATASET\\Tarea carga'\n",
    "df = pd.read_excel(files[2])\n",
    "for y in year:\n",
    "    if not os.path.exists(path+\"\\\\\"+str(y)):\n",
    "            os.mkdir(path+\"\\\\\"+str(y))\n",
    "    writer = pd.ExcelWriter(path+\"\\\\\"+str(y)+\"\\\\\"+'anual.xlsx', engine='xlsxwriter')\n",
    "    for m in month:\n",
    "        tmp_csv = df[(df['Order Date'].dt.year==y) & (df['Order Date'].dt.month==m)&  (df['Data_origen']==0)  ]\n",
    "        tmp_excel = df[(df['Order Date'].dt.year==y) & (df['Order Date'].dt.month==m)&  (df['Data_origen']==1)  ]\n",
    "        #Si la ruta no existe la creara\n",
    "        tmp_excel.to_excel( writer,sheet_name = dic.get(m),index=False)\n",
    "        tmp_csv.to_csv(path+\"\\\\\"+str(y)+\"\\\\\"+dic.get(m)+\".csv\",index=False)\n",
    "    writer.close()\n",
    "    \n",
    "##### Solo cambiar el path del codigo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "186a1c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tips para realizar la tarea\n",
    "path = r'D:\\ANALYTIC_PYTHON\\EntornoPython\\ETL DATASET\\Tarea carga'\n",
    "#pista utilice estos codigos para ver los xlsx y los csv , debe utilizar loops para cargar los archivos\n",
    "flujo_excel = glob.glob(f'{path}/*/*.xlsx', recursive=True)\n",
    "flujo_csv =glob.glob(f'{path}/*/*.csv', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "989d0f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#para el flujo csv\n",
    "# Creamos una lista en blanco para cargar los datasets\n",
    "li = []\n",
    "# Realizaremos un loop sobre cada archivo, lo leeremos y lo juntaremos.\n",
    "\n",
    "for f in flujo_csv:\n",
    "    # Leemos el archivo\n",
    "    temp_df = pd.read_csv(f ,sep=',')\n",
    "    # agregamos a la lista los dataframes\n",
    "    li.append(temp_df)\n",
    "    #print(f'Dataframe creado exitosamente para {f} con un tamañao {temp_df.shape}')\n",
    "\n",
    "# Uniremos todos los dataframe en uno\n",
    "df_csv = pd.concat(li, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e839ba2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flujo Excel\n",
    "import openpyxl\n",
    "li = []\n",
    "# Realizaremos un loop sobre cada archivo, lo leeremos y lo juntaremos.\n",
    "for f in flujo_excel:\n",
    "    # Leemos el archivo\n",
    "    wb = openpyxl.load_workbook(f)\n",
    "    #leer las hojas\n",
    "    hojas_Excel = wb.sheetnames\n",
    "    # creear un loop que entre y jale la informacion de cada pestaña\n",
    "    df_Excel = []\n",
    "    for hoja in hojas_Excel:\n",
    "        tmp = pd.read_excel(f,sheet_name = hoja ) \n",
    "        df_Excel.append(temp_df)\n",
    "    df_excel_consolidado = pd.concat(df_Excel, axis=0)\n",
    "\n",
    "    # agregamos a la lista los dataframes\n",
    "    li.append(df_excel_consolidado)\n",
    "    #print(f'Dataframe creado exitosamente para {f} con un tamañao {temp_df.shape}')\n",
    "\n",
    "# Uniremos todos los dataframe en uno\n",
    "df_Excel = pd.concat(li, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "42a0204c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_25528\\3028009854.py:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_final = df_Excel.append(df_csv)\n"
     ]
    }
   ],
   "source": [
    "#Finalmente consolido tanto el excel como el csv\n",
    "\n",
    "df_final = df_Excel.append(df_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "50dc50e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(\"datos_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6aa36c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Noviembre', 'Junio', 'Octubre', 'Abril', 'Diciembre', 'Mayo', 'Agosto', 'Julio', 'Septiembre', 'Enero', 'Marzo', 'Febrero']\n"
     ]
    }
   ],
   "source": [
    "#tips 2 este codigo permite visualizar las pestañas de cada archivo excel, se debe realizar un loop sobre cada archivo excel\n",
    "import openpyxl\n",
    "wb = openpyxl.load_workbook(path +'\\\\2014\\\\anual.xlsx')\n",
    "print(wb.sheetnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0c530016",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Row ID</th>\n",
       "      <th>Order ID</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Ship Date</th>\n",
       "      <th>Ship Mode</th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>Segment</th>\n",
       "      <th>Country</th>\n",
       "      <th>City</th>\n",
       "      <th>...</th>\n",
       "      <th>Region</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Sub-Category</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Profit</th>\n",
       "      <th>Data_origen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79</td>\n",
       "      <td>US-2014-147606</td>\n",
       "      <td>2014-11-26</td>\n",
       "      <td>2014-12-01</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>JE-15745</td>\n",
       "      <td>Joel Eaton</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Houston</td>\n",
       "      <td>...</td>\n",
       "      <td>Central</td>\n",
       "      <td>FUR-FU-10003194</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Furnishings</td>\n",
       "      <td>Eldon Expressions Desk Accessory, Wood Pencil ...</td>\n",
       "      <td>19.30</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-14.4750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>183</td>\n",
       "      <td>CA-2014-158274</td>\n",
       "      <td>2014-11-19</td>\n",
       "      <td>2014-11-24</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>RM-19675</td>\n",
       "      <td>Robert Marley</td>\n",
       "      <td>Home Office</td>\n",
       "      <td>United States</td>\n",
       "      <td>Monroe</td>\n",
       "      <td>...</td>\n",
       "      <td>South</td>\n",
       "      <td>TEC-PH-10003273</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Phones</td>\n",
       "      <td>AT&amp;T TR1909W</td>\n",
       "      <td>503.96</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131.0296</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>184</td>\n",
       "      <td>CA-2014-158274</td>\n",
       "      <td>2014-11-19</td>\n",
       "      <td>2014-11-24</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>RM-19675</td>\n",
       "      <td>Robert Marley</td>\n",
       "      <td>Home Office</td>\n",
       "      <td>United States</td>\n",
       "      <td>Monroe</td>\n",
       "      <td>...</td>\n",
       "      <td>South</td>\n",
       "      <td>TEC-PH-10004896</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Phones</td>\n",
       "      <td>Nokia Lumia 521 (T-Mobile)</td>\n",
       "      <td>149.95</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.9860</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>319</td>\n",
       "      <td>CA-2014-164973</td>\n",
       "      <td>2014-11-04</td>\n",
       "      <td>2014-11-09</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>NM-18445</td>\n",
       "      <td>Nathan Mautz</td>\n",
       "      <td>Home Office</td>\n",
       "      <td>United States</td>\n",
       "      <td>New York City</td>\n",
       "      <td>...</td>\n",
       "      <td>East</td>\n",
       "      <td>TEC-MA-10002927</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Machines</td>\n",
       "      <td>Canon imageCLASS MF7460 Monochrome Digital Las...</td>\n",
       "      <td>3991.98</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1995.9900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>320</td>\n",
       "      <td>CA-2014-164973</td>\n",
       "      <td>2014-11-04</td>\n",
       "      <td>2014-11-09</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>NM-18445</td>\n",
       "      <td>Nathan Mautz</td>\n",
       "      <td>Home Office</td>\n",
       "      <td>United States</td>\n",
       "      <td>New York City</td>\n",
       "      <td>...</td>\n",
       "      <td>East</td>\n",
       "      <td>TEC-PH-10004093</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Phones</td>\n",
       "      <td>Panasonic Kx-TS550</td>\n",
       "      <td>275.94</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0226</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Row ID        Order ID Order Date  Ship Date       Ship Mode Customer ID  \\\n",
       "0      79  US-2014-147606 2014-11-26 2014-12-01    Second Class    JE-15745   \n",
       "1     183  CA-2014-158274 2014-11-19 2014-11-24    Second Class    RM-19675   \n",
       "2     184  CA-2014-158274 2014-11-19 2014-11-24    Second Class    RM-19675   \n",
       "3     319  CA-2014-164973 2014-11-04 2014-11-09  Standard Class    NM-18445   \n",
       "4     320  CA-2014-164973 2014-11-04 2014-11-09  Standard Class    NM-18445   \n",
       "\n",
       "   Customer Name      Segment        Country           City  ...   Region  \\\n",
       "0     Joel Eaton     Consumer  United States        Houston  ...  Central   \n",
       "1  Robert Marley  Home Office  United States         Monroe  ...    South   \n",
       "2  Robert Marley  Home Office  United States         Monroe  ...    South   \n",
       "3   Nathan Mautz  Home Office  United States  New York City  ...     East   \n",
       "4   Nathan Mautz  Home Office  United States  New York City  ...     East   \n",
       "\n",
       "        Product ID    Category Sub-Category  \\\n",
       "0  FUR-FU-10003194   Furniture  Furnishings   \n",
       "1  TEC-PH-10003273  Technology       Phones   \n",
       "2  TEC-PH-10004896  Technology       Phones   \n",
       "3  TEC-MA-10002927  Technology     Machines   \n",
       "4  TEC-PH-10004093  Technology       Phones   \n",
       "\n",
       "                                        Product Name    Sales Quantity  \\\n",
       "0  Eldon Expressions Desk Accessory, Wood Pencil ...    19.30        5   \n",
       "1                                       AT&T TR1909W   503.96        4   \n",
       "2                         Nokia Lumia 521 (T-Mobile)   149.95        5   \n",
       "3  Canon imageCLASS MF7460 Monochrome Digital Las...  3991.98        2   \n",
       "4                                 Panasonic Kx-TS550   275.94        6   \n",
       "\n",
       "   Discount     Profit  Data_origen  \n",
       "0       0.6   -14.4750            1  \n",
       "1       0.0   131.0296            1  \n",
       "2       0.0    41.9860            1  \n",
       "3       0.0  1995.9900            1  \n",
       "4       0.0    80.0226            1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tips 3\n",
    "# Para cargar una hoja especifica de un excel se debe realizar lo siguiente\n",
    "tmp = pd.read_excel(path +'\\\\2014\\\\anual.xlsx',sheet_name = 'Noviembre' ) \n",
    "tmp.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf2fd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Debe cargar todos los archivos tanto en csv y en excel y unirlos todo en un solo file\n",
    "#Deben guardar el archivo final en la carpeta con el nombre consolidado.xlsx\n",
    "\n",
    "#enviar el codigo final en un word con fotos del proceso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ae75d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tips para realizar la tarea\n",
    "path = r'D:\\ANALYTIC_PYTHON\\EntornoPython\\ETL DATASET\\Tarea carga'\n",
    "#pista utilice estos codigos para ver los xlsx y los csv , debe utilizar loops para cargar los archivos\n",
    "flujo_excel = glob.glob(f'{path}/*/*.xlsx', recursive=True)\n",
    "flujo_csv =glob.glob(f'{path}/*/*.csv', recursive=True)\n",
    "\n",
    "#para el flujo csv\n",
    "# Creamos una lista en blanco para cargar los datasets\n",
    "li = []\n",
    "# Realizaremos un loop sobre cada archivo, lo leeremos y lo juntaremos.\n",
    "\n",
    "for f in flujo_csv:\n",
    "    # Leemos el archivo\n",
    "    temp_df = pd.read_csv(f ,sep=',')\n",
    "    # agregamos a la lista los dataframes\n",
    "    li.append(temp_df)\n",
    "    #print(f'Dataframe creado exitosamente para {f} con un tamañao {temp_df.shape}')\n",
    "\n",
    "# Uniremos todos los dataframe en uno\n",
    "df_csv = pd.concat(li, axis=0)\n",
    "\n",
    "#Finalmente consolido tanto el excel como el csv\n",
    "\n",
    "df_final = df_Excel.append(df_csv)\n",
    "\n",
    "df_final.to_csv(\"datos_final\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
