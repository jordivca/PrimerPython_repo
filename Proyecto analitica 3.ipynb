{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbbf8878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carga de datos\n",
      "Limpieza de datos\n",
      "Datos para modelar\n",
      "Modelando\n",
      "Modelando : entrenamiento\n",
      "knn Accuracy_train 0.7083333333333334 Accuracy_test 0.7674418604651163\n",
      "knn               precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.81      0.85      0.83        20\n",
      "         2.0       0.62      0.73      0.67        11\n",
      "         3.0       1.00      1.00      1.00         7\n",
      "         4.0       0.00      0.00      0.00         3\n",
      "         6.0       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.77        43\n",
      "   macro avg       0.68      0.62      0.63        43\n",
      "weighted avg       0.74      0.77      0.75        43\n",
      "\n",
      "cart Accuracy_train 1.0 Accuracy_test 0.7906976744186046\n",
      "cart               precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.90      0.90      0.90        20\n",
      "         2.0       0.78      0.64      0.70        11\n",
      "         3.0       1.00      0.86      0.92         7\n",
      "         4.0       0.50      0.67      0.57         3\n",
      "         5.0       0.00      0.00      0.00         0\n",
      "         6.0       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.79        43\n",
      "   macro avg       0.70      0.59      0.63        43\n",
      "weighted avg       0.86      0.79      0.82        43\n",
      "\n",
      "svm Accuracy_train 0.3869047619047619 Accuracy_test 0.2558139534883721\n",
      "svm               precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        20\n",
      "         2.0       0.26      1.00      0.41        11\n",
      "         3.0       0.00      0.00      0.00         7\n",
      "         4.0       0.00      0.00      0.00         3\n",
      "         6.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.26        43\n",
      "   macro avg       0.05      0.20      0.08        43\n",
      "weighted avg       0.07      0.26      0.10        43\n",
      "\n",
      "bayes Accuracy_train 0.5833333333333334 Accuracy_test 0.6976744186046512\n",
      "bayes               precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.77      0.85      0.81        20\n",
      "         2.0       0.67      0.36      0.47        11\n",
      "         3.0       1.00      1.00      1.00         7\n",
      "         4.0       0.00      0.00      0.00         3\n",
      "         5.0       0.00      0.00      0.00         0\n",
      "         6.0       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.70        43\n",
      "   macro avg       0.57      0.54      0.55        43\n",
      "weighted avg       0.74      0.70      0.71        43\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\BCP\\ALGORTIMO\\Curso_ETL_Python\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "D:\\BCP\\ALGORTIMO\\Curso_ETL_Python\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "D:\\BCP\\ALGORTIMO\\Curso_ETL_Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\BCP\\ALGORTIMO\\Curso_ETL_Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\BCP\\ALGORTIMO\\Curso_ETL_Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\BCP\\ALGORTIMO\\Curso_ETL_Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\BCP\\ALGORTIMO\\Curso_ETL_Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\BCP\\ALGORTIMO\\Curso_ETL_Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\BCP\\ALGORTIMO\\Curso_ETL_Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\BCP\\ALGORTIMO\\Curso_ETL_Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\BCP\\ALGORTIMO\\Curso_ETL_Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\BCP\\ALGORTIMO\\Curso_ETL_Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\BCP\\ALGORTIMO\\Curso_ETL_Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\BCP\\ALGORTIMO\\Curso_ETL_Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdm Accuracy_train 1.0 Accuracy_test 0.8372093023255814\n",
      "rdm               precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.86      0.95      0.90        20\n",
      "         2.0       0.86      0.55      0.67        11\n",
      "         3.0       0.88      1.00      0.93         7\n",
      "         4.0       0.67      0.67      0.67         3\n",
      "         5.0       0.00      0.00      0.00         0\n",
      "         6.0       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.84        43\n",
      "   macro avg       0.71      0.69      0.70        43\n",
      "weighted avg       0.86      0.84      0.84        43\n",
      "\n",
      "lgc Accuracy_train 0.6130952380952381 Accuracy_test 0.6046511627906976\n",
      "lgc               precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.86      0.60      0.71        20\n",
      "         2.0       0.35      0.64      0.45        11\n",
      "         3.0       1.00      1.00      1.00         7\n",
      "         4.0       0.00      0.00      0.00         3\n",
      "         5.0       0.00      0.00      0.00         0\n",
      "         6.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.60        43\n",
      "   macro avg       0.37      0.37      0.36        43\n",
      "weighted avg       0.65      0.60      0.61        43\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\BCP\\ALGORTIMO\\Curso_ETL_Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\BCP\\ALGORTIMO\\Curso_ETL_Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\BCP\\ALGORTIMO\\Curso_ETL_Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\BCP\\ALGORTIMO\\Curso_ETL_Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\BCP\\ALGORTIMO\\Curso_ETL_Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\BCP\\ALGORTIMO\\Curso_ETL_Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\BCP\\ALGORTIMO\\Curso_ETL_Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\BCP\\ALGORTIMO\\Curso_ETL_Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\BCP\\ALGORTIMO\\Curso_ETL_Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\BCP\\ALGORTIMO\\Curso_ETL_Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\BCP\\ALGORTIMO\\Curso_ETL_Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\BCP\\ALGORTIMO\\Curso_ETL_Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ada Accuracy_train 0.5059523809523809 Accuracy_test 0.37209302325581395\n",
      "ada               precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        20\n",
      "         2.0       0.29      0.91      0.43        11\n",
      "         3.0       1.00      0.86      0.92         7\n",
      "         4.0       0.00      0.00      0.00         3\n",
      "         5.0       0.00      0.00      0.00         0\n",
      "         6.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.37        43\n",
      "   macro avg       0.21      0.29      0.23        43\n",
      "weighted avg       0.24      0.37      0.26        43\n",
      "\n",
      "gda Accuracy_train 1.0 Accuracy_test 0.813953488372093\n",
      "gda               precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.90      0.90      0.90        20\n",
      "         2.0       0.70      0.64      0.67        11\n",
      "         3.0       1.00      1.00      1.00         7\n",
      "         4.0       0.50      0.33      0.40         3\n",
      "         5.0       0.00      0.00      0.00         0\n",
      "         6.0       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.81        43\n",
      "   macro avg       0.68      0.64      0.66        43\n",
      "weighted avg       0.84      0.81      0.83        43\n",
      "\n",
      "bca Accuracy_train 0.9761904761904762 Accuracy_test 0.7209302325581395\n",
      "bca               precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.82      0.70      0.76        20\n",
      "         2.0       0.58      0.64      0.61        11\n",
      "         3.0       0.88      1.00      0.93         7\n",
      "         4.0       0.50      0.67      0.57         3\n",
      "         5.0       0.00      0.00      0.00         0\n",
      "         6.0       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.72        43\n",
      "   macro avg       0.63      0.58      0.59        43\n",
      "weighted avg       0.76      0.72      0.73        43\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\BCP\\ALGORTIMO\\Curso_ETL_Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\BCP\\ALGORTIMO\\Curso_ETL_Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\BCP\\ALGORTIMO\\Curso_ETL_Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\BCP\\ALGORTIMO\\Curso_ETL_Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\BCP\\ALGORTIMO\\Curso_ETL_Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\BCP\\ALGORTIMO\\Curso_ETL_Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#importando libreria\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#cargamos los datos\n",
    "print(\"Carga de datos\")\n",
    "glass_data = pd.read_csv(\"glass.csv\")\n",
    "#crearemos una variable target con valores numericos\n",
    "glass_data['Type'] = np.where(glass_data['Type']=='building_windows_float_processed',1,\n",
    "                             np.where(glass_data['Type']=='building_windows_non_float_processed',2,\n",
    "                                     np.where(glass_data['Type']=='headlamps',3,\n",
    "                                             np.where(glass_data['Type']=='vehicle_windows_float_processed',4,\n",
    "                                                     np.where(glass_data['Type']=='containers',5,\n",
    "                                                             np.where(glass_data['Type']=='tableware',6,\n",
    "                                                        np.nan))))))\n",
    "\n",
    "#limpieza de datos\n",
    "print(\"Limpieza de datos\")\n",
    "q3, q1 = np.percentile(glass_data['K'], [75, 25])\n",
    "iqr = q3 - q1\n",
    "glass_data['K_outlier'] = np.where((glass_data['K']>q3+1.5*iqr) | (glass_data['K']<q1-1.5*iqr) ,1,0)\n",
    "glass_data = glass_data[glass_data['K']<=2]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#seleccionamos las variables\n",
    "print(\"Datos para modelar\")\n",
    "X = glass_data[['RI', 'Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba', 'Fe']]\n",
    "y = glass_data['Type']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "#modelamiento\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "print(\"Modelando\")\n",
    "models = {}\n",
    "models['knn'] = KNeighborsClassifier()                #### K-neighbors\n",
    "models['cart'] = DecisionTreeClassifier()             #### Decision Tree\n",
    "models['svm'] = SVC()                                 #### Support vector machine\n",
    "models['bayes'] = GaussianNB()                        #### Naive Bayes\n",
    "models['rdm'] = RandomForestClassifier()              #### Random Forest\n",
    "models['lgc'] = LogisticRegression(max_iter=1000)     #### Logistic Reggresion\n",
    "models['ada'] = AdaBoostClassifier()                  #### Adaboost\n",
    "models['gda'] = GradientBoostingClassifier()          #### Gradient Boosting\n",
    "models['bca'] = BaggingClassifier()                   #### Bagging\n",
    "print(\"Modelando : entrenamiento\")\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy_train = accuracy_score(y_train,y_pred_train)\n",
    "    accuracy = accuracy_score(y_test,y_pred)\n",
    "    #auc_score = metrics.roc_auc_score( y_test, y_pred,  )\n",
    "    classification = classification_report(y_test,y_pred)\n",
    "    print(name, 'Accuracy_train',accuracy_train,'Accuracy_test',accuracy)\n",
    "    print(name, classification)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "498bb22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\BCP\\ALGORTIMO\\Curso_ETL_Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\BCP\\ALGORTIMO\\Curso_ETL_Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\BCP\\ALGORTIMO\\Curso_ETL_Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\BCP\\ALGORTIMO\\Curso_ETL_Python\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.82      0.90      0.86        20\n",
      "         2.0       0.78      0.64      0.70        11\n",
      "         3.0       1.00      1.00      1.00         7\n",
      "         4.0       0.50      0.33      0.40         3\n",
      "         5.0       0.00      0.00      0.00         0\n",
      "         6.0       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.79        43\n",
      "   macro avg       0.68      0.56      0.60        43\n",
      "weighted avg       0.82      0.79      0.80        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Prediccion\n",
    "y_pred = model.predict(X_test)\n",
    "#Reporte\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred ))\n",
    "#List Hyperparameters that we want to tune.\n",
    "\n",
    "n_estimators = list(range(30,35))\n",
    "max_features = list(range(5,10))\n",
    "max_samples=list(range(30,35))\n",
    "\n",
    "#Convert to dictionary\n",
    "hyperparameters = dict(n_estimators=n_estimators, max_features=max_features, max_samples=max_samples)\n",
    "#Create new KNN object\n",
    "bca = BaggingClassifier() \n",
    "#Use GridSearch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "clf = GridSearchCV(bca, hyperparameters, cv=10)\n",
    "#Fit the model\n",
    "best_model = clf.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cf207b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best n_estimators: 31\n",
      "Best max_feature: 6\n",
      "Best max_samples: 33\n"
     ]
    }
   ],
   "source": [
    "#Print The value of best Hyperparameters\n",
    "print('Best n_estimators:', best_model.best_estimator_.get_params()['n_estimators'])\n",
    "print('Best max_feature:', best_model.best_estimator_.get_params()['max_features'])\n",
    "print('Best max_samples:', best_model.best_estimator_.get_params()['max_samples'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45155a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.78      0.90      0.84        20\n",
      "         2.0       0.60      0.55      0.57        11\n",
      "         3.0       1.00      1.00      1.00         7\n",
      "         4.0       0.00      0.00      0.00         3\n",
      "         5.0       0.00      0.00      0.00         0\n",
      "         6.0       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.74        43\n",
      "   macro avg       0.56      0.49      0.51        43\n",
      "weighted avg       0.73      0.74      0.73        43\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\BCP\\ALGORTIMO\\Curso_ETL_Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\BCP\\ALGORTIMO\\Curso_ETL_Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\BCP\\ALGORTIMO\\Curso_ETL_Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\BCP\\ALGORTIMO\\Curso_ETL_Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\BCP\\ALGORTIMO\\Curso_ETL_Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\BCP\\ALGORTIMO\\Curso_ETL_Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model = BaggingClassifier(n_estimators=31,max_features=6,max_samples=33)\n",
    "model.fit(X_train, y_train)\n",
    "#Prediccion\n",
    "y_pred = model.predict(X_test)\n",
    "#Reporte\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "442c34c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#guardando el modelo final\n",
    "from pickle import dump\n",
    "from pickle import load\n",
    "def guardar_modelo(model,nombre):\n",
    "    output = open(nombre, 'wb')\n",
    "    dump(model, output , -1)\n",
    "    output.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6aa87678",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cargar modelo \n",
    "def cargar_modelo(nombre):\n",
    "    input = open(nombre, 'rb')\n",
    "    modelo = load(input)\n",
    "    input.close()\n",
    "    return modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc669bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre = 'modelo.pkl'\n",
    "guardar_modelo(model,nombre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d0b7de94",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_final = cargar_modelo(nombre)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "877ce96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "por_predecir = pd.DataFrame([[0.51811, 0.29600, \n",
    "                              3.96000e+00, 1.43000, 7.2920,\n",
    "        9.00000, 0.79000e+00, 3.40000e-01, 2.5]],columns = ['RI', 'Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba' ,'Fe'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7be25fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo_final.predict(por_predecir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34586b05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
